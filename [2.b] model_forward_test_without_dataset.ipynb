{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_multimodal_rcnn_model\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CPU]\n"
     ]
    }
   ],
   "source": [
    "# clean gpu memory and tell pytorch to use deterministic algorithm.\n",
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "labels_cols = DEFAULT_REFLACX_LABEL_COLS\n",
    "iou_thrs = np.array([0.5])\n",
    "\n",
    "common_args = {\n",
    "    \"save_early_stop_model\": True,\n",
    "    \"optimiser\": \"sgd\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"image_backbone_pretrained\": True,\n",
    "    \"fixation_backbone_pretrained\": True,\n",
    "    \"record_training_performance\": True,\n",
    "    \"dataset_mode\": \"normal\",\n",
    "    \"image_size\": 512,\n",
    "    \"batch_size\": 4,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"reduceLROnPlateau_factor\": 0.1,\n",
    "    \"reduceLROnPlateau_patience\": 999,\n",
    "    \"reduceLROnPlateau_full_stop\": True,\n",
    "    \"multiStepLR_milestones\": 100,\n",
    "    \"multiStepLR_gamma\": 0.1,\n",
    "    \"use_mask\": True,\n",
    "    \"gt_in_train_till\": 999,\n",
    "    \"box_head_dropout_rate\": 0,\n",
    "    \"measure_test\": True,\n",
    "}\n",
    "\n",
    "fusion_add_args = {\n",
    "    \"fuse_depth\": 0,\n",
    "    \"fusion_residule\": False,\n",
    "    \"fusion_strategy\": \"add\", \n",
    "}\n",
    "\n",
    "small_model_args = {\n",
    "    \"mask_hidden_layers\": 64,\n",
    "    \"fuse_conv_channels\": 64,\n",
    "    \"representation_size\": 64, \n",
    "    \"backbone_out_channels\": 64,\n",
    "}\n",
    "\n",
    "mobilenet_args = {\n",
    "    \"backbone\": \"mobilenet_v3\",\n",
    "    \"using_fpn\": False,\n",
    "}\n",
    "\n",
    "\n",
    "# [TODO]: clean the model setup for fixation map.\n",
    "model_setup = ModelSetup(\n",
    "        name=\"forward_testing_model\",\n",
    "        use_fixations=True,\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **fusion_add_args,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate datasets and dataloaders\n",
    "The batch size is also defined in this section. For testing purpose, we only set it as 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params_dict = {\n",
    "    \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "    \"dataset_mode\": model_setup.dataset_mode,\n",
    "    \"bbox_to_mask\": model_setup.use_mask,\n",
    "    \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "}\n",
    "\n",
    "detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "    dataset_params_dict=dataset_params_dict\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example instance from dataset:\n",
    "Inside each instance we have:\n",
    "\n",
    "- Images\n",
    "- Fixation heatmaps\n",
    "- Targets (Dictionary)\n",
    "\n",
    "And, inside the target, there're:\n",
    "\n",
    "- boxes (bounding boxes of abnormality)\n",
    "- label (disease index (Note: the class **0** means the background))\n",
    "- image_id (idx to get that image)\n",
    "- area (the areas that bouding boxes contain)\n",
    "- iscrowd (if it's a place with multiple bouding boxes, we assume all the the bouding boxes are not crowd.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of a training instance - images, fixations, targets = 3\n",
      "Each image has 3 channels \n"
     ]
    }
   ],
   "source": [
    "# sizes of train, val and test are correct\n",
    "\n",
    "# \n",
    "print(f'Size of a training instance - images, fixations, targets = {len(train_dataset[0])}')\n",
    "\n",
    "# \n",
    "print(f'Each image has {len(train_dataset[0][0])} channels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[ 568., 1533., 1309., 2199.],\n",
       "         [ 523., 1723.,  675., 2211.]], dtype=torch.float64),\n",
       " 'labels': tensor([1, 2]),\n",
       " 'image_id': tensor([0]),\n",
       " 'area': tensor([493506.,  74176.], dtype=torch.float64),\n",
       " 'iscrowd': tensor([0, 0]),\n",
       " 'dicom_id': 'd1bdf0b5-cf2d6aee-0685203b-23334088-a5ed5401',\n",
       " 'image_path': 'D:\\\\XAMI-MIMIC\\\\patient_17799242\\\\CXR-JPG\\\\s53582712\\\\d1bdf0b5-cf2d6aee-0685203b-23334088-a5ed5401.jpg',\n",
       " 'fixations_path': 'D:\\\\XAMI-MIMIC\\\\patient_17799242\\\\CXR-JPG\\\\s53582712\\\\time_heatmap_P202R293587.jpg',\n",
       " 'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "train_dataset[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained backbone. mobilenet_v3\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "forward_testing_model will use mask, [64] layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalMaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (fixation_backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (rpn): XAMIRegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(64, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): XAMIRoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): XAMITwoMLPHead(\n",
       "      (fc6): Sequential(\n",
       "        (0): Linear(in_features=3136, out_features=64, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "      (fc7): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=64, out_features=3, bias=True)\n",
       "      (bbox_pred): Linear(in_features=64, out_features=12, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_multimodal_rcnn_model(\n",
    "    labels_cols,\n",
    "    model_setup,\n",
    "    rpn_nms_thresh=0.3,\n",
    "    box_detections_per_img=10,\n",
    "    box_nms_thresh=0.2,\n",
    "    rpn_score_thresh=0.0,\n",
    "    box_score_thresh=0.05,\n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data to feed\n",
    "We prepare three main data to test the model:\n",
    "\n",
    "- CXR image\n",
    "- Fixation heatmaps\n",
    "- Target\n",
    "\n",
    "And, for each data, we adjust the format to what the model expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "data = train_dataset.prepare_input_from_data(data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0039,  ..., 0.0157, 0.0157, 0.0353],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0118, 0.0275],\n",
       "           [0.0039, 0.0000, 0.0000,  ..., 0.0353, 0.0235, 0.0353]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0039,  ..., 0.0157, 0.0157, 0.0353],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0118, 0.0275],\n",
       "           [0.0039, 0.0000, 0.0000,  ..., 0.0353, 0.0235, 0.0353]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0039,  ..., 0.0157, 0.0157, 0.0353],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0118, 0.0275],\n",
       "           [0.0039, 0.0000, 0.0000,  ..., 0.0353, 0.0235, 0.0353]]]),\n",
       "  tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           ...,\n",
       "           [0.3843, 0.3922, 0.4039,  ..., 0.8471, 0.8588, 0.0000],\n",
       "           [0.3882, 0.3882, 0.4039,  ..., 0.8431, 0.8431, 0.0039],\n",
       "           [0.3804, 0.3961, 0.4235,  ..., 0.8353, 0.8353, 0.0000]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           ...,\n",
       "           [0.3843, 0.3922, 0.4039,  ..., 0.8471, 0.8588, 0.0000],\n",
       "           [0.3882, 0.3882, 0.4039,  ..., 0.8431, 0.8431, 0.0039],\n",
       "           [0.3804, 0.3961, 0.4235,  ..., 0.8353, 0.8353, 0.0000]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
       "           ...,\n",
       "           [0.3843, 0.3922, 0.4039,  ..., 0.8471, 0.8588, 0.0000],\n",
       "           [0.3882, 0.3882, 0.4039,  ..., 0.8431, 0.8431, 0.0039],\n",
       "           [0.3804, 0.3961, 0.4235,  ..., 0.8353, 0.8353, 0.0000]]])],\n",
       " [tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feedforward (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "loss_dict, outputs = model(*data[:-1], targets=data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, fixations, targets = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "original_image_sizes= []\n",
    "for img in images:\n",
    "    val = img.shape[-2:]\n",
    "    assert len(val) == 2\n",
    "    original_image_sizes.append((val[0], val[1]))\n",
    "\n",
    "images, targets = model.transform(images, targets)\n",
    "\n",
    "img_features = model.backbone(images.tensors)\n",
    "\n",
    "print(img_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Four different losses are given in the output\n",
    "\n",
    "We will use these losses to optimise the network while training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feedforward\n",
    "\n",
    "### Detection.\n",
    "\n",
    "A detection contain *boxes*, *lables*, and *scores*.\n",
    "\n",
    "- *boxes*: All the bounding boxes for this image. \n",
    "- *labels*: Labels corresponded to the bounding boxes.\n",
    "- *score*: Score (Confidence) for each boudning box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss_classifier': tensor(1.0743, grad_fn=<NllLossBackward0>),\n",
       "  'loss_box_reg': tensor(0.0014, grad_fn=<DivBackward0>),\n",
       "  'loss_mask': tensor(0.7265, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       "  'loss_objectness': tensor(0.6926, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       "  'loss_rpn_box_reg': tensor(0.0034, dtype=torch.float64, grad_fn=<DivBackward0>)},\n",
       " [{'boxes': tensor([[   0.0000,  383.0743,  633.2679, 1151.3854],\n",
       "           [ 422.0579,  612.9487,  527.7842,  897.1188],\n",
       "           [ 270.7764, 1585.4551,  707.8502, 1861.1404],\n",
       "           [ 264.2876,  607.8674,  367.8270,  891.1305],\n",
       "           [ 106.5293, 1949.2998,  548.1766, 2221.8372],\n",
       "           [ 724.0617,  719.5476, 1161.2401, 1778.1035],\n",
       "           [ 899.0967, 1188.8501, 1006.4523, 1470.1182],\n",
       "           [1147.2544, 1081.5037, 1387.4926, 1213.4926],\n",
       "           [ 528.9288, 1844.8662,  757.8915, 1966.3760],\n",
       "           [1000.9653, 2227.5544, 1225.6404, 2352.8313]],\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2]),\n",
       "   'scores': tensor([0.4130, 0.4057, 0.4002, 0.3980, 0.3946, 0.3934, 0.3843, 0.3799, 0.3759,\n",
       "           0.3749], grad_fn=<IndexBackward0>),\n",
       "   'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<UnsqueezeBackward0>)},\n",
       "  {'boxes': tensor([[6.3531e+02, 0.0000e+00, 9.4535e+02, 3.6254e+02],\n",
       "           [9.9816e+02, 3.1589e+02, 1.2281e+03, 4.4588e+02],\n",
       "           [6.8097e+02, 0.0000e+00, 9.0605e+02, 6.3717e+01],\n",
       "           [1.0679e+03, 1.1836e+03, 1.4835e+03, 1.4706e+03],\n",
       "           [7.4907e+02, 2.4654e+02, 1.1943e+03, 5.2498e+02],\n",
       "           [2.3248e+02, 0.0000e+00, 2.0195e+03, 8.5799e+02],\n",
       "           [1.5341e+03, 0.0000e+00, 1.9681e+03, 1.2746e+02],\n",
       "           [9.6030e+00, 6.3382e+02, 3.8036e+02, 9.1131e+02],\n",
       "           [1.4638e+03, 5.0342e+02, 1.6881e+03, 6.3170e+02],\n",
       "           [1.2481e+00, 6.9855e+02, 1.1383e+02, 8.2293e+02]],\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       "   'scores': tensor([0.4020, 0.3872, 0.3859, 0.3844, 0.3805, 0.3800, 0.3767, 0.3766, 0.3762,\n",
       "           0.3761], grad_fn=<IndexBackward0>),\n",
       "   'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<UnsqueezeBackward0>)}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/philferriere/cocoapi.git to c:\\users\\utilizador\\appdata\\local\\temp\\pip-req-build-yh1gskmk\n",
      "  Resolved https://github.com/philferriere/cocoapi.git to commit 2929bd2ef6b451054755dfd7ceb09278f935f7ad\n",
      "Building wheels for collected packages: pycocotools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/philferriere/cocoapi.git 'C:\\Users\\Utilizador\\AppData\\Local\\Temp\\pip-req-build-yh1gskmk'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for pycocotools (setup.py): started\n",
      "  Building wheel for pycocotools (setup.py): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0-cp39-cp39-win_amd64.whl size=81991 sha256=2bb632cc2c2b576b4beaca5d6de5a363083304508965cc6df30b271d278e15de\n",
      "  Stored in directory: C:\\Users\\Utilizador\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-zv44n6yy\\wheels\\8d\\25\\59\\5840f59a3c30bac7223e8d0f1dcf19ec4d3c249d7659d9782f\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils.print as print_f\n",
    "\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from utils.engine import get_iou_types\n",
    "from utils.engine import xami_train_one_epoch, xami_evaluate\n",
    "from utils.plot import plot_losses, plot_ap_ars\n",
    "from utils.save import get_data_from_metric_logger\n",
    "from utils.coco_utils import get_cocos\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_multimodal_rcnn_model\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ap_ar, get_ap_ar_for_train_val\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from models.dynamic_loss import DynamicWeightedLoss\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "from  datetime import datetime\n",
    "import torch.optim as optim\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Preparing for the training.====================\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "forward_testing_model will use mask, [64] layers.\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "[model]: 4,749,149\n",
      "[model.backbone]: 1,258,848\n",
      "[model.rpn]: 41,803\n",
      "[model.roi_heads]: 2,189,650\n",
      "[model.roi_heads.box_head]: 204,928\n",
      "[model.roi_heads.box_head.fc6]: 200,768\n",
      "[model.roi_heads.box_head.fc7]: 4,160\n",
      "[model.roi_heads.box_predictor]: 975\n",
      "[model.roi_heads.mask_head]: 1,917,952\n",
      "Using SGD as optimizer with lr=0.001\n",
      "====================Start training. Preparing Tooke [25] sec====================\n",
      "====================Training model: [forward_testing_model]====================\n",
      "========================================For Training [forward_testing_model]========================================\n",
      "ModelSetup(dataset_mode='normal', name='forward_testing_model', use_fixations=True, save_early_stop_model=True, record_training_performance=True, backbone='mobilenet_v3', optimiser='sgd', lr=0.001, weight_decay=1e-05, image_backbone_pretrained=True, fixation_backbone_pretrained=True, image_size=512, backbone_out_channels=64, batch_size=4, warmup_epochs=0, lr_scheduler='ReduceLROnPlateau', reduceLROnPlateau_factor=0.1, reduceLROnPlateau_patience=999, reduceLROnPlateau_full_stop=True, multiStepLR_milestones=100, multiStepLR_gamma=0.1, representation_size=64, mask_hidden_layers=64, using_fpn=False, use_mask=True, fuse_conv_channels=64, box_head_dropout_rate=0, fuse_depth=0, fusion_strategy='add', fusion_residule=False, gt_in_train_till=999, measure_test=True)\n",
      "====================================================================================================================\n",
      "\n",
      "Best AP validation model has been saved to: [None]\n",
      "Best AR validation model has been saved to: [None]\n",
      "The final model has been saved to: [None]\n",
      "\n",
      "====================================================================================================================\n",
      "Epoch: [1]  [ 0/11]  eta: 0:00:59  lr: 0.001000  loss: 2.7953 (2.7953)  loss_classifier: 1.1034 (1.1034)  loss_box_reg: 0.0051 (0.0051)  loss_mask: 0.9910 (0.9910)  loss_objectness: 0.6926 (0.6926)  loss_rpn_box_reg: 0.0033 (0.0033)  time: 5.4474  data: 1.3764\n",
      "Epoch: [1]  [10/11]  eta: 0:00:05  lr: 0.001000  loss: 2.2348 (2.2688)  loss_classifier: 0.9995 (0.9730)  loss_box_reg: 0.0052 (0.0082)  loss_mask: 0.5361 (0.5917)  loss_objectness: 0.6916 (0.6918)  loss_rpn_box_reg: 0.0033 (0.0042)  time: 5.1700  data: 1.6404\n",
      "Epoch: [1] Total time: 0:00:56 (5.1708 s / it)\n",
      "Averaged stats: lr: 0.001000  loss: 2.2348 (2.2688)  loss_classifier: 0.9995 (0.9730)  loss_box_reg: 0.0052 (0.0082)  loss_mask: 0.5361 (0.5917)  loss_objectness: 0.6916 (0.6918)  loss_rpn_box_reg: 0.0033 (0.0042)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable MetricLogger object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_5128/4234733660.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         train_info.last_train_evaluator, train_loger = xami_train_one_epoch(\n\u001b[0m\u001b[0;32m    108\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable MetricLogger object"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_infos = []\n",
    "\n",
    "all_model_setups = [\n",
    "    ModelSetup(\n",
    "        name=\"forward_testing_model\",\n",
    "        use_fixations=True,\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **fusion_add_args,\n",
    "    )\n",
    "]\n",
    "\n",
    "for model_setup in all_model_setups:\n",
    "\n",
    "    print_f.print_title(\"Preparing for the training.\")\n",
    "\n",
    "    train_info = TrainingInfo(model_setup)\n",
    "\n",
    "    if model_setup.measure_test:\n",
    "        # initialise the test recording list.\n",
    "        train_info.test_ap_ars = []\n",
    "\n",
    "    model = create_multimodal_rcnn_model(\n",
    "            labels_cols,\n",
    "            model_setup,\n",
    "            rpn_nms_thresh=0.3,\n",
    "            box_detections_per_img=10,\n",
    "            box_nms_thresh=0.2,\n",
    "            rpn_score_thresh=0.0,\n",
    "            box_score_thresh=0.05,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    ################ Datasets ################\n",
    "    dataset_params_dict = {\n",
    "            \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "            \"dataset_mode\": model_setup.dataset_mode,\n",
    "            \"bbox_to_mask\": model_setup.use_mask,\n",
    "            \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "    }\n",
    "\n",
    "    detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "            dataset_params_dict=dataset_params_dict\n",
    "    )\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "            train_dataset, val_dataset, test_dataset, batch_size=2\n",
    "    )\n",
    "\n",
    "    train_coco, val_coco, test_coco = get_cocos(\n",
    "            train_dataloader, val_dataloader, test_dataloader\n",
    "    )\n",
    "\n",
    "    # eval_params_dict = get_eval_params_dict(\n",
    "    #         detect_eval_dataset, iou_thrs=iou_thrs, use_iobb=use_iobb,\n",
    "    # )\n",
    "\n",
    "    # dynamic_loss_weight = None\n",
    "    loss_keys = [\n",
    "            \"loss_classifier\",\n",
    "            \"loss_box_reg\",\n",
    "            \"loss_objectness\",\n",
    "            \"loss_rpn_box_reg\",\n",
    "    ]\n",
    "            \n",
    "    dynamic_loss_weight = DynamicWeightedLoss(\n",
    "            keys=loss_keys + [\"loss_mask\"] if model_setup.use_mask else loss_keys\n",
    "    )\n",
    "    dynamic_loss_weight.to(device)\n",
    "    print_params_setup(model)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if dynamic_loss_weight:\n",
    "        params += [p for p in dynamic_loss_weight.parameters() if p.requires_grad]\n",
    "\n",
    "    iou_types = get_iou_types(model, model_setup)\n",
    "    optimizer = get_optimiser(params, model_setup)\n",
    "    lr_scheduler = get_lr_scheduler(optimizer, model_setup)\n",
    "\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    print_f.print_title(\n",
    "        f\"Start training. Preparing Tooke [{ (current_time - train_info.start_t).seconds}] sec\"\n",
    "    )\n",
    "\n",
    "    train_info.start_t = datetime.now()\n",
    "\n",
    "    val_loss = None\n",
    "\n",
    "    ## Start the training from here.\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        print_f.print_title(f\"Training model: [{model_setup.name}]\")\n",
    "        print(train_info)\n",
    "\n",
    "        train_info.epoch = e + 1\n",
    "\n",
    "        if train_info.epoch > model_setup.gt_in_train_till:\n",
    "            model.roi_heads.use_gt_in_train  = False\n",
    "\n",
    "        ###### Perform training and show the training result here ######\n",
    "        model.train()\n",
    "\n",
    "        train_info.last_train_evaluator, train_loger = xami_train_one_epoch(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                data_loader=train_dataloader,\n",
    "                device=device,\n",
    "                epoch=train_info.epoch,\n",
    "                print_freq=10,\n",
    "                iou_types=iou_types,\n",
    "                coco=train_coco,\n",
    "                score_thres=None,\n",
    "                evaluate_on_run=True,\n",
    "                params_dict=eval_params_dict,\n",
    "                dynamic_loss_weight=dynamic_loss_weight,\n",
    "        )\n",
    "\n",
    "        # train_info.train_evaluators.append(train_evaluator)\n",
    "        train_info.train_losses.append(get_data_from_metric_logger(train_loger))\n",
    "        ################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_input = [torch.randn(( 3, 512, 512)).to(device)]\n",
    "example_fixations_input = [torch.randn(( 3, 512, 512)).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "model(example_image_input, fixations=example_fixations_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37134ace218921b74af13dd92c56fdadfb15c5b94d65c3fac1e4c7a849f19ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
