{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_multimodal_rcnn_model\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "# clean gpu memory and tell pytorch to use deterministic algorithm.\n",
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "labels_cols = DEFAULT_REFLACX_LABEL_COLS\n",
    "iou_thrs = np.array([0.5])\n",
    "\n",
    "common_args = {\n",
    "    \"save_early_stop_model\": True,\n",
    "    \"optimiser\": \"sgd\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"image_backbone_pretrained\": True,\n",
    "    \"fixation_backbone_pretrained\": True,\n",
    "    \"record_training_performance\": True,\n",
    "    \"image_size\": 256,\n",
    "    \"batch_size\": 4,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"reduceLROnPlateau_factor\": 0.1,\n",
    "    \"reduceLROnPlateau_patience\": 999,\n",
    "    \"reduceLROnPlateau_full_stop\": True,\n",
    "    \"multiStepLR_milestones\": 100,\n",
    "    \"multiStepLR_gamma\": 0.1,\n",
    "    \"use_mask\": True,\n",
    "    \"gt_in_train_till\": 999,\n",
    "    \"box_head_dropout_rate\": 0,\n",
    "    \"measure_test\": True,\n",
    "}\n",
    "\n",
    "fusion_add_args = {\n",
    "    \"fuse_depth\": 0,\n",
    "    \"fusion_residule\": False,\n",
    "    \"fusion_strategy\": \"add\", \n",
    "}\n",
    "\n",
    "small_model_args = {\n",
    "    \"mask_hidden_layers\": 64,\n",
    "    \"fuse_conv_channels\": 64,\n",
    "    \"representation_size\": 64, \n",
    "    \"backbone_out_channels\": 64,\n",
    "}\n",
    "\n",
    "mobilenet_args = {\n",
    "    \"backbone\": \"mobilenet_v3\",\n",
    "    \"using_fpn\": False,\n",
    "}\n",
    "\n",
    "\n",
    "# [TODO]: clean the model setup for fixation map.\n",
    "model_setup = ModelSetup(\n",
    "        name=\"forward_testing_model\",\n",
    "        use_fixations=True,\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **fusion_add_args,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate datasets and dataloaders\n",
    "The batch size is also defined in this section. For testing purpose, we only set it as 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params_dict = {\n",
    "    \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "    \"bbox_to_mask\": model_setup.use_mask,\n",
    "    \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "    \"with_fixation\": True\n",
    "}\n",
    "\n",
    "detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "    dataset_params_dict=dataset_params_dict\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example instance from dataset:\n",
    "Inside each instance we have:\n",
    "\n",
    "- Images\n",
    "- Fixation heatmaps\n",
    "- Targets (Dictionary)\n",
    "\n",
    "And, inside the target, there're:\n",
    "\n",
    "- boxes (bounding boxes of abnormality)\n",
    "- label (disease index (Note: the class **0** means the background))\n",
    "- image_id (idx to get that image)\n",
    "- area (the areas that bouding boxes contain)\n",
    "- iscrowd (if it's a place with multiple bouding boxes, we assume all the the bouding boxes are not crowd.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of a training instance - images, fixations, targets = 3\n",
      "Each image has 3 channels \n"
     ]
    }
   ],
   "source": [
    "# sizes of train, val and test are correct\n",
    "\n",
    "# \n",
    "print(f'Size of a training instance - images, fixations, targets = {len(train_dataset[0])}')\n",
    "\n",
    "# \n",
    "print(f'Each image has {len(train_dataset[0][0])} channels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([], size=(0, 4), dtype=torch.float64),\n",
       " 'labels': tensor([], dtype=torch.int64),\n",
       " 'image_id': tensor([0]),\n",
       " 'area': tensor([], dtype=torch.float64),\n",
       " 'iscrowd': tensor([], dtype=torch.int64),\n",
       " 'dicom_id': '34cedb74-d0996b40-6d218312-a9174bea-d48dc033',\n",
       " 'image_path': 'D:\\\\XAMI-MIMIC\\\\patient_18111516\\\\CXR-JPG\\\\s55032240\\\\34cedb74-d0996b40-6d218312-a9174bea-d48dc033.jpg',\n",
       " 'fixations_path': 'D:\\\\XAMI-MIMIC\\\\patient_18111516\\\\REFLACX\\\\P102R108387\\\\fixations.csv',\n",
       " 'masks': tensor([], size=(0, 3056, 2544), dtype=torch.uint8)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "train_dataset[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained backbone. mobilenet_v3\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "forward_testing_model will use mask, [64] layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultimodalMaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (fixation_backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (rpn): XAMIRegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(64, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): XAMIRoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): XAMITwoMLPHead(\n",
       "      (fc6): Sequential(\n",
       "        (0): Linear(in_features=3136, out_features=64, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "      (fc7): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): Dropout2d(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=64, out_features=4, bias=True)\n",
       "      (bbox_pred): Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_multimodal_rcnn_model(\n",
    "    labels_cols,\n",
    "    model_setup,\n",
    "    rpn_nms_thresh=0.3,\n",
    "    box_detections_per_img=10,\n",
    "    box_nms_thresh=0.2,\n",
    "    rpn_score_thresh=0.0,\n",
    "    box_score_thresh=0.05,\n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data to feed\n",
    "We prepare three main data to test the model:\n",
    "\n",
    "- CXR image\n",
    "- Fixation heatmaps\n",
    "- Target\n",
    "\n",
    "And, for each data, we adjust the format to what the model expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "data = train_dataset.prepare_input_from_data(data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           ...,\n",
       "           [0.7686, 0.7725, 0.7451,  ..., 0.8667, 0.8627, 0.8588],\n",
       "           [0.7725, 0.7725, 0.7490,  ..., 0.8706, 0.8627, 0.8627],\n",
       "           [0.7725, 0.7686, 0.7529,  ..., 0.8588, 0.8471, 0.8510]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           ...,\n",
       "           [0.7686, 0.7725, 0.7451,  ..., 0.8667, 0.8627, 0.8588],\n",
       "           [0.7725, 0.7725, 0.7490,  ..., 0.8706, 0.8627, 0.8627],\n",
       "           [0.7725, 0.7686, 0.7529,  ..., 0.8588, 0.8471, 0.8510]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           ...,\n",
       "           [0.7686, 0.7725, 0.7451,  ..., 0.8667, 0.8627, 0.8588],\n",
       "           [0.7725, 0.7725, 0.7490,  ..., 0.8706, 0.8627, 0.8627],\n",
       "           [0.7725, 0.7686, 0.7529,  ..., 0.8588, 0.8471, 0.8510]]],\n",
       "         device='cuda:0')],\n",
       " [tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feedforward (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "loss_dict, outputs = model(*data[:-1], targets=data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(1.3321, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(0., device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'loss_mask': tensor(0., device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'loss_objectness': tensor(0.6932, device='cuda:0',\n",
       "        grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0., device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, fixations, targets = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "original_image_sizes= []\n",
    "for img in images:\n",
    "    val = img.shape[-2:]\n",
    "    assert len(val) == 2\n",
    "    original_image_sizes.append((val[0], val[1]))\n",
    "\n",
    "images, targets = model.transform(images, targets)\n",
    "\n",
    "img_features = model.backbone(images.tensors)\n",
    "\n",
    "print(img_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Four different losses are given in the output\n",
    "\n",
    "We will use these losses to optimise the network while training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feedforward\n",
    "\n",
    "### Detection.\n",
    "\n",
    "A detection contain *boxes*, *lables*, and *scores*.\n",
    "\n",
    "- *boxes*: All the bounding boxes for this image. \n",
    "- *labels*: Labels corresponded to the bounding boxes.\n",
    "- *score*: Score (Confidence) for each boudning box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss_classifier': tensor(1.3321, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       "  'loss_box_reg': tensor(0., device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  'loss_mask': tensor(0., device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  'loss_objectness': tensor(0.6932, device='cuda:0',\n",
       "         grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       "  'loss_rpn_box_reg': tensor(0., device='cuda:0', grad_fn=<DivBackward0>)},\n",
       " [{'boxes': tensor([[ 587.8787,  740.5051, 1699.9360, 1174.5237],\n",
       "           [ 842.5342,  537.4828, 1411.8909,  725.8585],\n",
       "           [ 881.6542, 1784.5619, 1420.1460, 2539.0000],\n",
       "           [   0.0000,  195.6173,  270.5373, 1069.7511],\n",
       "           [ 494.5350,    9.1685, 1033.6853,  775.6381],\n",
       "           [  35.8862,    0.0000, 3050.0000, 2518.8296],\n",
       "           [1626.4299,  535.4458, 2202.1589,  737.1761],\n",
       "           [ 100.1350,  529.7561,  651.8814,  733.9246],\n",
       "           [   0.0000,   85.5293,  130.5414,  517.6898],\n",
       "           [1219.4171,  538.9279, 1783.7306,  732.5659]], device='cuda:0',\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([2, 2, 1, 2, 1, 1, 1, 2, 2, 2], device='cuda:0'),\n",
       "   'scores': tensor([0.3046, 0.2995, 0.2989, 0.2961, 0.2953, 0.2947, 0.2940, 0.2938, 0.2930,\n",
       "           0.2917], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       "   'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "   \n",
       "   \n",
       "           [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
       "          grad_fn=<UnsqueezeBackward0>)}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_input = [torch.randn(( 3, 512, 512)).to(device)]\n",
    "example_fixations_input = [torch.randn(( 3, 512, 512)).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({},\n",
       " [{'boxes': tensor([[8.1641e+01, 1.5629e-01, 1.7483e+02, 2.1994e+01],\n",
       "           [1.0299e+02, 2.7746e-01, 2.8554e+02, 4.6092e+01],\n",
       "           [2.0970e+02, 1.3748e-01, 3.0301e+02, 2.2135e+01],\n",
       "           [3.2266e-01, 1.3106e-01, 4.6674e+01, 2.2030e+01],\n",
       "           [2.7398e+02, 1.4030e-01, 3.6709e+02, 2.2213e+01],\n",
       "           [4.0171e+02, 4.2666e+02, 4.9510e+02, 4.7021e+02],\n",
       "           [4.0143e+02, 3.6310e+02, 4.9460e+02, 4.0608e+02],\n",
       "           [2.4051e-01, 1.4798e+00, 4.6261e+01, 1.5444e+02],\n",
       "           [3.5861e+02, 6.2046e-01, 5.1200e+02, 4.5563e+01],\n",
       "           [2.3159e+02, 1.9150e+01, 4.1401e+02, 1.1025e+02]], device='cuda:0',\n",
       "          grad_fn=<StackBackward0>),\n",
       "   'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       "   'scores': tensor([0.2850, 0.2849, 0.2843, 0.2842, 0.2841, 0.2833, 0.2821, 0.2807, 0.2795,\n",
       "           0.2795], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       "   'masks': tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             ...,\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "   \n",
       "   \n",
       "           [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             ...,\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "   \n",
       "   \n",
       "           [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             ...,\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[0.0339, 0.0807, 0.0761,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0771, 0.1837, 0.1734,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.1203, 0.2867, 0.2706,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             ...,\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "   \n",
       "   \n",
       "           [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.2185, 0.1881, 0.1485],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.4981, 0.4286, 0.3383],\n",
       "             ...,\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "   \n",
       "   \n",
       "           [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             ...,\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "             [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "          device='cuda:0', grad_fn=<UnsqueezeBackward0>)}])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "model(example_image_input, fixations=example_fixations_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to run with training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dynamic_loss import DynamicWeightedLoss\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup\n",
    "from utils.engine import xami_train_one_epoch, xami_evaluate, get_iou_types\n",
    "from  datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model]: 4,749,539\n",
      "[model.backbone]: 1,258,848\n",
      "[model.rpn]: 41,803\n",
      "[model.roi_heads]: 2,190,040\n",
      "[model.roi_heads.box_head]: 204,928\n",
      "[model.roi_heads.box_head.fc6]: 200,768\n",
      "[model.roi_heads.box_head.fc7]: 4,160\n",
      "[model.roi_heads.box_predictor]: 1,300\n",
      "[model.roi_heads.mask_head]: 1,917,952\n",
      "Using SGD as optimizer with lr=0.001\n"
     ]
    }
   ],
   "source": [
    "loss_keys = [\n",
    "    \"loss_classifier\",\n",
    "    \"loss_box_reg\",\n",
    "    \"loss_objectness\",\n",
    "    \"loss_rpn_box_reg\",\n",
    "]\n",
    "\n",
    "dynamic_loss_weight = DynamicWeightedLoss(\n",
    "    keys=loss_keys + [\"loss_mask\"] if model_setup.use_mask else loss_keys\n",
    ")\n",
    "dynamic_loss_weight.to(device)\n",
    "print_params_setup(model)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "if dynamic_loss_weight:\n",
    "    params += [p for p in dynamic_loss_weight.parameters() if p.requires_grad]\n",
    "\n",
    "iou_types = get_iou_types(model, model_setup)\n",
    "optimizer = get_optimiser(params, model_setup)\n",
    "lr_scheduler = get_lr_scheduler(optimizer, model_setup)\n",
    "\n",
    "current_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/2122]  eta: 0:44:20  lr: 0.001000  loss: 2.0230 (2.0230)  loss_classifier: 1.3305 (1.3305)  loss_box_reg: 0.0000 (0.0000)  loss_mask: 0.0000 (0.0000)  loss_objectness: 0.6925 (0.6925)  loss_rpn_box_reg: 0.0000 (0.0000)  time: 1.2536  data: 0.5017  max mem: 1459\n",
      "Epoch: [0]  [  10/2122]  eta: 0:20:17  lr: 0.001000  loss: 1.9991 (2.2360)  loss_classifier: 1.2492 (1.2381)  loss_box_reg: 0.0000 (0.0069)  loss_mask: 0.0000 (0.2956)  loss_objectness: 0.6921 (0.6921)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.5763  data: 0.3409  max mem: 1816\n",
      "Epoch: [0]  [  20/2122]  eta: 0:18:49  lr: 0.001000  loss: 1.9413 (2.0940)  loss_classifier: 1.0634 (1.0087)  loss_box_reg: 0.0000 (0.0223)  loss_mask: 0.0000 (0.3673)  loss_objectness: 0.6915 (0.6911)  loss_rpn_box_reg: 0.0000 (0.0044)  time: 0.5014  data: 0.3177  max mem: 1816\n",
      "Epoch: [0]  [  30/2122]  eta: 0:18:20  lr: 0.001000  loss: 1.3928 (1.7779)  loss_classifier: 0.3050 (0.7387)  loss_box_reg: 0.0143 (0.0282)  loss_mask: 0.3319 (0.3187)  loss_objectness: 0.6865 (0.6885)  loss_rpn_box_reg: 0.0020 (0.0038)  time: 0.4982  data: 0.3140  max mem: 1816\n",
      "Epoch: [0]  [  40/2122]  eta: 0:17:58  lr: 0.001000  loss: 1.0079 (1.5832)  loss_classifier: 0.1323 (0.5887)  loss_box_reg: 0.0253 (0.0401)  loss_mask: 0.0810 (0.2663)  loss_objectness: 0.6769 (0.6842)  loss_rpn_box_reg: 0.0020 (0.0037)  time: 0.4978  data: 0.3159  max mem: 1816\n",
      "Epoch: [0]  [  50/2122]  eta: 0:17:34  lr: 0.001000  loss: 0.8846 (1.4747)  loss_classifier: 0.1199 (0.4947)  loss_box_reg: 0.0582 (0.0479)  loss_mask: 0.0734 (0.2509)  loss_objectness: 0.6592 (0.6775)  loss_rpn_box_reg: 0.0035 (0.0038)  time: 0.4831  data: 0.3122  max mem: 1816\n",
      "Epoch: [0]  [  60/2122]  eta: 0:17:28  lr: 0.001000  loss: 0.8527 (1.3787)  loss_classifier: 0.0840 (0.4295)  loss_box_reg: 0.0068 (0.0460)  loss_mask: 0.0567 (0.2300)  loss_objectness: 0.6403 (0.6696)  loss_rpn_box_reg: 0.0017 (0.0037)  time: 0.4890  data: 0.3121  max mem: 1816\n",
      "Epoch: [0]  [  70/2122]  eta: 0:17:17  lr: 0.001000  loss: 0.8021 (1.3034)  loss_classifier: 0.0840 (0.3819)  loss_box_reg: 0.0062 (0.0430)  loss_mask: 0.0923 (0.2155)  loss_objectness: 0.6142 (0.6593)  loss_rpn_box_reg: 0.0013 (0.0038)  time: 0.4973  data: 0.3114  max mem: 1819\n",
      "Epoch: [0]  [  80/2122]  eta: 0:17:07  lr: 0.001000  loss: 0.6224 (1.2263)  loss_classifier: 0.0407 (0.3405)  loss_box_reg: 0.0000 (0.0398)  loss_mask: 0.0000 (0.1984)  loss_objectness: 0.5650 (0.6442)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4861  data: 0.3112  max mem: 1819\n",
      "Epoch: [0]  [  90/2122]  eta: 0:16:59  lr: 0.001000  loss: 0.6201 (1.1761)  loss_classifier: 0.0829 (0.3128)  loss_box_reg: 0.0025 (0.0381)  loss_mask: 0.0528 (0.1980)  loss_objectness: 0.4833 (0.6236)  loss_rpn_box_reg: 0.0021 (0.0036)  time: 0.4869  data: 0.3178  max mem: 1819\n",
      "Epoch: [0]  [ 100/2122]  eta: 0:16:45  lr: 0.001000  loss: 0.5926 (1.1072)  loss_classifier: 0.0829 (0.2867)  loss_box_reg: 0.0029 (0.0354)  loss_mask: 0.0842 (0.1847)  loss_objectness: 0.3943 (0.5970)  loss_rpn_box_reg: 0.0026 (0.0034)  time: 0.4751  data: 0.3073  max mem: 1819\n",
      "Epoch: [0]  [ 110/2122]  eta: 0:16:40  lr: 0.001000  loss: 0.3836 (1.0460)  loss_classifier: 0.0205 (0.2658)  loss_box_reg: 0.0000 (0.0330)  loss_mask: 0.0000 (0.1794)  loss_objectness: 0.2889 (0.5645)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4773  data: 0.3063  max mem: 1819\n",
      "Epoch: [0]  [ 120/2122]  eta: 0:16:36  lr: 0.001000  loss: 0.3010 (0.9970)  loss_classifier: 0.0497 (0.2519)  loss_box_reg: 0.0027 (0.0326)  loss_mask: 0.0352 (0.1785)  loss_objectness: 0.1856 (0.5307)  loss_rpn_box_reg: 0.0013 (0.0034)  time: 0.4981  data: 0.3235  max mem: 1819\n",
      "Epoch: [0]  [ 130/2122]  eta: 0:16:24  lr: 0.001000  loss: 0.3375 (0.9508)  loss_classifier: 0.0630 (0.2398)  loss_box_reg: 0.0091 (0.0318)  loss_mask: 0.1282 (0.1771)  loss_objectness: 0.1311 (0.4985)  loss_rpn_box_reg: 0.0013 (0.0036)  time: 0.4765  data: 0.3093  max mem: 1819\n",
      "Epoch: [0]  [ 140/2122]  eta: 0:16:18  lr: 0.001000  loss: 0.2295 (0.9034)  loss_classifier: 0.0564 (0.2286)  loss_box_reg: 0.0039 (0.0313)  loss_mask: 0.0643 (0.1713)  loss_objectness: 0.0894 (0.4685)  loss_rpn_box_reg: 0.0028 (0.0037)  time: 0.4710  data: 0.3075  max mem: 1819\n",
      "Epoch: [0]  [ 150/2122]  eta: 0:16:09  lr: 0.001000  loss: 0.1715 (0.8607)  loss_classifier: 0.0428 (0.2178)  loss_box_reg: 0.0020 (0.0300)  loss_mask: 0.0541 (0.1684)  loss_objectness: 0.0542 (0.4408)  loss_rpn_box_reg: 0.0012 (0.0036)  time: 0.4749  data: 0.3063  max mem: 1819\n",
      "Epoch: [0]  [ 160/2122]  eta: 0:16:01  lr: 0.001000  loss: 0.1865 (0.8214)  loss_classifier: 0.0428 (0.2073)  loss_box_reg: 0.0020 (0.0288)  loss_mask: 0.0551 (0.1656)  loss_objectness: 0.0418 (0.4160)  loss_rpn_box_reg: 0.0012 (0.0037)  time: 0.4649  data: 0.2953  max mem: 1819\n",
      "Epoch: [0]  [ 170/2122]  eta: 0:15:53  lr: 0.001000  loss: 0.1871 (0.7877)  loss_classifier: 0.0464 (0.1986)  loss_box_reg: 0.0055 (0.0278)  loss_mask: 0.0550 (0.1636)  loss_objectness: 0.0340 (0.3938)  loss_rpn_box_reg: 0.0040 (0.0038)  time: 0.4671  data: 0.2980  max mem: 1819\n",
      "Epoch: [0]  [ 180/2122]  eta: 0:15:47  lr: 0.001000  loss: 0.1871 (0.7546)  loss_classifier: 0.0481 (0.1899)  loss_box_reg: 0.0008 (0.0266)  loss_mask: 0.0499 (0.1607)  loss_objectness: 0.0338 (0.3737)  loss_rpn_box_reg: 0.0013 (0.0038)  time: 0.4700  data: 0.2932  max mem: 1819\n",
      "Epoch: [0]  [ 190/2122]  eta: 0:15:40  lr: 0.001000  loss: 0.0337 (0.7196)  loss_classifier: 0.0125 (0.1813)  loss_box_reg: 0.0000 (0.0253)  loss_mask: 0.0000 (0.1539)  loss_objectness: 0.0187 (0.3554)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4703  data: 0.2893  max mem: 1819\n",
      "Epoch: [0]  [ 200/2122]  eta: 0:15:34  lr: 0.001000  loss: 0.0337 (0.7091)  loss_classifier: 0.0150 (0.1743)  loss_box_reg: 0.0000 (0.0243)  loss_mask: 0.0000 (0.1679)  loss_objectness: 0.0187 (0.3388)  loss_rpn_box_reg: 0.0000 (0.0038)  time: 0.4710  data: 0.2957  max mem: 1819\n",
      "Epoch: [0]  [ 210/2122]  eta: 0:15:31  lr: 0.001000  loss: 0.1658 (0.6993)  loss_classifier: 0.0572 (0.1724)  loss_box_reg: 0.0025 (0.0239)  loss_mask: 0.0386 (0.1736)  loss_objectness: 0.0277 (0.3253)  loss_rpn_box_reg: 0.0065 (0.0040)  time: 0.4896  data: 0.3161  max mem: 1819\n",
      "Epoch: [0]  [ 220/2122]  eta: 0:15:26  lr: 0.001000  loss: 0.3892 (0.6909)  loss_classifier: 0.0701 (0.1675)  loss_box_reg: 0.0026 (0.0231)  loss_mask: 0.2124 (0.1836)  loss_objectness: 0.0427 (0.3127)  loss_rpn_box_reg: 0.0020 (0.0040)  time: 0.4951  data: 0.3174  max mem: 1819\n",
      "Epoch: [0]  [ 230/2122]  eta: 0:15:19  lr: 0.001000  loss: 0.2021 (0.6757)  loss_classifier: 0.0566 (0.1631)  loss_box_reg: 0.0010 (0.0223)  loss_mask: 0.1047 (0.1854)  loss_objectness: 0.0356 (0.3008)  loss_rpn_box_reg: 0.0020 (0.0041)  time: 0.4757  data: 0.3008  max mem: 1819\n",
      "Epoch: [0]  [ 240/2122]  eta: 0:15:12  lr: 0.001000  loss: 0.0302 (0.6557)  loss_classifier: 0.0165 (0.1585)  loss_box_reg: 0.0000 (0.0217)  loss_mask: 0.0000 (0.1821)  loss_objectness: 0.0200 (0.2894)  loss_rpn_box_reg: 0.0000 (0.0040)  time: 0.4617  data: 0.2954  max mem: 1819\n",
      "Epoch: [0]  [ 250/2122]  eta: 0:15:07  lr: 0.001000  loss: 0.1410 (0.6402)  loss_classifier: 0.0395 (0.1547)  loss_box_reg: 0.0005 (0.0211)  loss_mask: 0.0751 (0.1809)  loss_objectness: 0.0247 (0.2794)  loss_rpn_box_reg: 0.0012 (0.0041)  time: 0.4712  data: 0.3012  max mem: 1819\n",
      "Epoch: [0]  [ 260/2122]  eta: 0:15:02  lr: 0.001000  loss: 0.1585 (0.6290)  loss_classifier: 0.0395 (0.1509)  loss_box_reg: 0.0005 (0.0206)  loss_mask: 0.0782 (0.1836)  loss_objectness: 0.0247 (0.2698)  loss_rpn_box_reg: 0.0021 (0.0041)  time: 0.4843  data: 0.3076  max mem: 1819\n",
      "Epoch: [0]  [ 270/2122]  eta: 0:14:59  lr: 0.001000  loss: 0.2987 (0.6300)  loss_classifier: 0.0392 (0.1484)  loss_box_reg: 0.0006 (0.0203)  loss_mask: 0.1030 (0.1961)  loss_objectness: 0.0239 (0.2611)  loss_rpn_box_reg: 0.0025 (0.0041)  time: 0.4935  data: 0.3173  max mem: 1819\n",
      "Epoch: [0]  [ 280/2122]  eta: 0:14:55  lr: 0.001000  loss: 0.5179 (0.6196)  loss_classifier: 0.0806 (0.1455)  loss_box_reg: 0.0012 (0.0198)  loss_mask: 0.3587 (0.1972)  loss_objectness: 0.0318 (0.2529)  loss_rpn_box_reg: 0.0040 (0.0041)  time: 0.5023  data: 0.3232  max mem: 1819\n",
      "Epoch: [0]  [ 290/2122]  eta: 0:14:49  lr: 0.001000  loss: 0.4452 (0.6180)  loss_classifier: 0.0839 (0.1437)  loss_box_reg: 0.0014 (0.0195)  loss_mask: 0.3197 (0.2051)  loss_objectness: 0.0382 (0.2455)  loss_rpn_box_reg: 0.0034 (0.0041)  time: 0.4864  data: 0.3106  max mem: 1819\n",
      "Epoch: [0]  [ 300/2122]  eta: 0:14:44  lr: 0.001000  loss: 0.2278 (0.6039)  loss_classifier: 0.0719 (0.1404)  loss_box_reg: 0.0010 (0.0191)  loss_mask: 0.0858 (0.2022)  loss_objectness: 0.0214 (0.2381)  loss_rpn_box_reg: 0.0022 (0.0040)  time: 0.4731  data: 0.2993  max mem: 1819\n",
      "Epoch: [0]  [ 310/2122]  eta: 0:14:39  lr: 0.001000  loss: 0.0284 (0.5912)  loss_classifier: 0.0174 (0.1373)  loss_box_reg: 0.0000 (0.0187)  loss_mask: 0.0000 (0.2002)  loss_objectness: 0.0099 (0.2311)  loss_rpn_box_reg: 0.0000 (0.0040)  time: 0.4812  data: 0.3003  max mem: 1819\n",
      "Epoch: [0]  [ 320/2122]  eta: 0:14:33  lr: 0.001000  loss: 0.2007 (0.5807)  loss_classifier: 0.0408 (0.1352)  loss_box_reg: 0.0002 (0.0187)  loss_mask: 0.1060 (0.1977)  loss_objectness: 0.0206 (0.2250)  loss_rpn_box_reg: 0.0023 (0.0041)  time: 0.4739  data: 0.3002  max mem: 1819\n",
      "Epoch: [0]  [ 330/2122]  eta: 0:14:27  lr: 0.001000  loss: 0.0353 (0.5676)  loss_classifier: 0.0264 (0.1320)  loss_box_reg: 0.0000 (0.0182)  loss_mask: 0.0000 (0.1947)  loss_objectness: 0.0090 (0.2186)  loss_rpn_box_reg: 0.0000 (0.0040)  time: 0.4661  data: 0.2973  max mem: 1819\n",
      "Epoch: [0]  [ 340/2122]  eta: 0:14:23  lr: 0.001000  loss: 0.1324 (0.5597)  loss_classifier: 0.0377 (0.1302)  loss_box_reg: 0.0005 (0.0180)  loss_mask: 0.0499 (0.1942)  loss_objectness: 0.0210 (0.2132)  loss_rpn_box_reg: 0.0028 (0.0041)  time: 0.4830  data: 0.3033  max mem: 1819\n",
      "Epoch: [0]  [ 350/2122]  eta: 0:14:17  lr: 0.001000  loss: 0.1667 (0.5476)  loss_classifier: 0.0536 (0.1278)  loss_box_reg: 0.0013 (0.0176)  loss_mask: 0.0694 (0.1903)  loss_objectness: 0.0293 (0.2078)  loss_rpn_box_reg: 0.0038 (0.0041)  time: 0.4823  data: 0.3029  max mem: 1819\n",
      "Epoch: [0]  [ 360/2122]  eta: 0:14:14  lr: 0.001000  loss: 0.1286 (0.5371)  loss_classifier: 0.0433 (0.1257)  loss_box_reg: 0.0010 (0.0173)  loss_mask: 0.0473 (0.1871)  loss_objectness: 0.0286 (0.2029)  loss_rpn_box_reg: 0.0036 (0.0041)  time: 0.4883  data: 0.3155  max mem: 1819\n",
      "Epoch: [0]  [ 370/2122]  eta: 0:14:08  lr: 0.001000  loss: 0.1273 (0.5313)  loss_classifier: 0.0432 (0.1235)  loss_box_reg: 0.0010 (0.0170)  loss_mask: 0.0390 (0.1886)  loss_objectness: 0.0211 (0.1981)  loss_rpn_box_reg: 0.0021 (0.0041)  time: 0.4906  data: 0.3231  max mem: 1819\n",
      "Epoch: [0]  [ 380/2122]  eta: 0:14:04  lr: 0.001000  loss: 0.3506 (0.5262)  loss_classifier: 0.0460 (0.1221)  loss_box_reg: 0.0001 (0.0168)  loss_mask: 0.2100 (0.1894)  loss_objectness: 0.0218 (0.1938)  loss_rpn_box_reg: 0.0013 (0.0041)  time: 0.4861  data: 0.3162  max mem: 1819\n",
      "Epoch: [0]  [ 390/2122]  eta: 0:13:59  lr: 0.001000  loss: 0.1737 (0.5170)  loss_classifier: 0.0460 (0.1202)  loss_box_reg: 0.0001 (0.0165)  loss_mask: 0.0881 (0.1869)  loss_objectness: 0.0218 (0.1894)  loss_rpn_box_reg: 0.0013 (0.0041)  time: 0.4880  data: 0.3149  max mem: 1819\n",
      "Epoch: [0]  [ 400/2122]  eta: 0:13:53  lr: 0.001000  loss: 0.0186 (0.5051)  loss_classifier: 0.0128 (0.1176)  loss_box_reg: 0.0000 (0.0162)  loss_mask: 0.0000 (0.1824)  loss_objectness: 0.0077 (0.1849)  loss_rpn_box_reg: 0.0000 (0.0040)  time: 0.4688  data: 0.2989  max mem: 1819\n",
      "Epoch: [0]  [ 410/2122]  eta: 0:13:48  lr: 0.001000  loss: 0.0157 (0.4986)  loss_classifier: 0.0090 (0.1159)  loss_box_reg: 0.0000 (0.0160)  loss_mask: 0.0000 (0.1819)  loss_objectness: 0.0057 (0.1808)  loss_rpn_box_reg: 0.0000 (0.0040)  time: 0.4735  data: 0.3013  max mem: 1819\n",
      "Epoch: [0]  [ 420/2122]  eta: 0:13:43  lr: 0.001000  loss: 0.0330 (0.4916)  loss_classifier: 0.0260 (0.1145)  loss_box_reg: 0.0000 (0.0157)  loss_mask: 0.0000 (0.1803)  loss_objectness: 0.0082 (0.1771)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4835  data: 0.3097  max mem: 1819\n",
      "Epoch: [0]  [ 430/2122]  eta: 0:13:39  lr: 0.001000  loss: 0.0404 (0.4844)  loss_classifier: 0.0338 (0.1129)  loss_box_reg: 0.0000 (0.0156)  loss_mask: 0.0000 (0.1785)  loss_objectness: 0.0071 (0.1734)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4875  data: 0.3089  max mem: 1819\n",
      "Epoch: [0]  [ 440/2122]  eta: 0:13:34  lr: 0.001000  loss: 0.0290 (0.4785)  loss_classifier: 0.0214 (0.1114)  loss_box_reg: 0.0000 (0.0153)  loss_mask: 0.0000 (0.1779)  loss_objectness: 0.0071 (0.1699)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4952  data: 0.3162  max mem: 1819\n",
      "Epoch: [0]  [ 450/2122]  eta: 0:13:28  lr: 0.001000  loss: 0.0214 (0.4705)  loss_classifier: 0.0158 (0.1097)  loss_box_reg: 0.0000 (0.0151)  loss_mask: 0.0000 (0.1753)  loss_objectness: 0.0066 (0.1666)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4732  data: 0.3029  max mem: 1819\n",
      "Epoch: [0]  [ 460/2122]  eta: 0:13:23  lr: 0.001000  loss: 0.0165 (0.4633)  loss_classifier: 0.0099 (0.1081)  loss_box_reg: 0.0000 (0.0149)  loss_mask: 0.0000 (0.1731)  loss_objectness: 0.0058 (0.1634)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4647  data: 0.2986  max mem: 1819\n",
      "Epoch: [0]  [ 470/2122]  eta: 0:13:19  lr: 0.001000  loss: 0.0184 (0.4564)  loss_classifier: 0.0121 (0.1067)  loss_box_reg: 0.0000 (0.0147)  loss_mask: 0.0000 (0.1708)  loss_objectness: 0.0064 (0.1603)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4886  data: 0.3170  max mem: 1819\n",
      "Epoch: [0]  [ 480/2122]  eta: 0:13:13  lr: 0.001000  loss: 0.1082 (0.4527)  loss_classifier: 0.0301 (0.1061)  loss_box_reg: 0.0003 (0.0148)  loss_mask: 0.0123 (0.1703)  loss_objectness: 0.0163 (0.1576)  loss_rpn_box_reg: 0.0018 (0.0039)  time: 0.4778  data: 0.3041  max mem: 1819\n",
      "Epoch: [0]  [ 490/2122]  eta: 0:13:09  lr: 0.001000  loss: 0.1082 (0.4459)  loss_classifier: 0.0307 (0.1047)  loss_box_reg: 0.0003 (0.0146)  loss_mask: 0.0123 (0.1679)  loss_objectness: 0.0185 (0.1547)  loss_rpn_box_reg: 0.0009 (0.0039)  time: 0.4770  data: 0.3022  max mem: 1819\n",
      "Epoch: [0]  [ 500/2122]  eta: 0:13:03  lr: 0.001000  loss: 0.0368 (0.4400)  loss_classifier: 0.0237 (0.1035)  loss_box_reg: 0.0000 (0.0145)  loss_mask: 0.0000 (0.1662)  loss_objectness: 0.0131 (0.1520)  loss_rpn_box_reg: 0.0000 (0.0039)  time: 0.4820  data: 0.3087  max mem: 1819\n",
      "Epoch: [0]  [ 510/2122]  eta: 0:12:58  lr: 0.001000  loss: 0.0196 (0.4347)  loss_classifier: 0.0146 (0.1022)  loss_box_reg: 0.0000 (0.0143)  loss_mask: 0.0000 (0.1650)  loss_objectness: 0.0070 (0.1493)  loss_rpn_box_reg: 0.0000 (0.0038)  time: 0.4681  data: 0.2969  max mem: 1819\n",
      "Epoch: [0]  [ 520/2122]  eta: 0:12:54  lr: 0.001000  loss: 0.0229 (0.4305)  loss_classifier: 0.0178 (0.1016)  loss_box_reg: 0.0000 (0.0143)  loss_mask: 0.0000 (0.1638)  loss_objectness: 0.0074 (0.1470)  loss_rpn_box_reg: 0.0000 (0.0038)  time: 0.4793  data: 0.3038  max mem: 1819\n",
      "Epoch: [0]  [ 530/2122]  eta: 0:12:48  lr: 0.001000  loss: 0.0229 (0.4247)  loss_classifier: 0.0178 (0.1004)  loss_box_reg: 0.0000 (0.0141)  loss_mask: 0.0000 (0.1619)  loss_objectness: 0.0064 (0.1445)  loss_rpn_box_reg: 0.0000 (0.0038)  time: 0.4681  data: 0.2965  max mem: 1819\n",
      "Epoch: [0]  [ 540/2122]  eta: 0:12:43  lr: 0.001000  loss: 0.0343 (0.4201)  loss_classifier: 0.0259 (0.0996)  loss_box_reg: 0.0000 (0.0141)  loss_mask: 0.0000 (0.1603)  loss_objectness: 0.0085 (0.1423)  loss_rpn_box_reg: 0.0000 (0.0038)  time: 0.4680  data: 0.2977  max mem: 1819\n",
      "Epoch: [0]  [ 550/2122]  eta: 0:12:38  lr: 0.001000  loss: 0.0926 (0.4142)  loss_classifier: 0.0304 (0.0983)  loss_box_reg: 0.0002 (0.0138)  loss_mask: 0.0352 (0.1583)  loss_objectness: 0.0165 (0.1400)  loss_rpn_box_reg: 0.0005 (0.0038)  time: 0.4772  data: 0.3064  max mem: 1819\n",
      "Epoch: [0]  [ 560/2122]  eta: 0:12:32  lr: 0.001000  loss: 0.0123 (0.4090)  loss_classifier: 0.0065 (0.0971)  loss_box_reg: 0.0000 (0.0136)  loss_mask: 0.0000 (0.1566)  loss_objectness: 0.0052 (0.1379)  loss_rpn_box_reg: 0.0000 (0.0038)  time: 0.4525  data: 0.2868  max mem: 1819\n",
      "Epoch: [0]  [ 570/2122]  eta: 0:12:27  lr: 0.001000  loss: 0.0135 (0.4056)  loss_classifier: 0.0090 (0.0963)  loss_box_reg: 0.0000 (0.0136)  loss_mask: 0.0000 (0.1561)  loss_objectness: 0.0058 (0.1358)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4623  data: 0.2901  max mem: 1819\n",
      "Epoch: [0]  [ 580/2122]  eta: 0:12:22  lr: 0.001000  loss: 0.0140 (0.4005)  loss_classifier: 0.0105 (0.0950)  loss_box_reg: 0.0000 (0.0134)  loss_mask: 0.0000 (0.1547)  loss_objectness: 0.0045 (0.1337)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4852  data: 0.3065  max mem: 1819\n",
      "Epoch: [0]  [ 590/2122]  eta: 0:12:17  lr: 0.001000  loss: 0.0213 (0.3981)  loss_classifier: 0.0145 (0.0944)  loss_box_reg: 0.0000 (0.0133)  loss_mask: 0.0000 (0.1548)  loss_objectness: 0.0067 (0.1318)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4839  data: 0.3092  max mem: 1819\n",
      "Epoch: [0]  [ 600/2122]  eta: 0:12:11  lr: 0.001000  loss: 0.0259 (0.3954)  loss_classifier: 0.0205 (0.0934)  loss_box_reg: 0.0000 (0.0132)  loss_mask: 0.0000 (0.1552)  loss_objectness: 0.0078 (0.1299)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4585  data: 0.2935  max mem: 1819\n",
      "Epoch: [0]  [ 610/2122]  eta: 0:12:06  lr: 0.001000  loss: 0.0237 (0.3914)  loss_classifier: 0.0166 (0.0925)  loss_box_reg: 0.0000 (0.0130)  loss_mask: 0.0000 (0.1540)  loss_objectness: 0.0066 (0.1282)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4496  data: 0.2864  max mem: 1819\n",
      "Epoch: [0]  [ 620/2122]  eta: 0:12:01  lr: 0.001000  loss: 0.0112 (0.3871)  loss_classifier: 0.0058 (0.0915)  loss_box_reg: 0.0000 (0.0130)  loss_mask: 0.0000 (0.1527)  loss_objectness: 0.0054 (0.1263)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4705  data: 0.3006  max mem: 1819\n",
      "Epoch: [0]  [ 630/2122]  eta: 0:11:56  lr: 0.001000  loss: 0.0109 (0.3824)  loss_classifier: 0.0061 (0.0905)  loss_box_reg: 0.0000 (0.0128)  loss_mask: 0.0000 (0.1510)  loss_objectness: 0.0044 (0.1245)  loss_rpn_box_reg: 0.0000 (0.0036)  time: 0.4675  data: 0.2976  max mem: 1819\n",
      "Epoch: [0]  [ 640/2122]  eta: 0:11:52  lr: 0.001000  loss: 0.0304 (0.3823)  loss_classifier: 0.0232 (0.0904)  loss_box_reg: 0.0000 (0.0130)  loss_mask: 0.0000 (0.1522)  loss_objectness: 0.0073 (0.1230)  loss_rpn_box_reg: 0.0000 (0.0037)  time: 0.4801  data: 0.3065  max mem: 1819\n",
      "Epoch: [0]  [ 650/2122]  eta: 0:11:47  lr: 0.001000  loss: 0.1433 (0.3796)  loss_classifier: 0.0456 (0.0897)  loss_box_reg: 0.0002 (0.0130)  loss_mask: 0.0759 (0.1519)  loss_objectness: 0.0154 (0.1214)  loss_rpn_box_reg: 0.0002 (0.0036)  time: 0.4956  data: 0.3171  max mem: 1819\n",
      "Epoch: [0]  [ 660/2122]  eta: 0:11:41  lr: 0.001000  loss: 0.0370 (0.3762)  loss_classifier: 0.0297 (0.0888)  loss_box_reg: 0.0000 (0.0129)  loss_mask: 0.0000 (0.1511)  loss_objectness: 0.0079 (0.1198)  loss_rpn_box_reg: 0.0000 (0.0036)  time: 0.4679  data: 0.2989  max mem: 1819\n",
      "Epoch: [0]  [ 670/2122]  eta: 0:11:37  lr: 0.001000  loss: 0.1469 (0.3747)  loss_classifier: 0.0357 (0.0885)  loss_box_reg: 0.0016 (0.0128)  loss_mask: 0.0582 (0.1513)  loss_objectness: 0.0216 (0.1184)  loss_rpn_box_reg: 0.0019 (0.0037)  time: 0.4694  data: 0.3013  max mem: 1819\n",
      "Epoch: [0]  [ 680/2122]  eta: 0:11:32  lr: 0.001000  loss: 0.2311 (0.3780)  loss_classifier: 0.0493 (0.0878)  loss_box_reg: 0.0022 (0.0128)  loss_mask: 0.1198 (0.1568)  loss_objectness: 0.0216 (0.1170)  loss_rpn_box_reg: 0.0025 (0.0036)  time: 0.4841  data: 0.3094  max mem: 1819\n",
      "Epoch: [0]  [ 690/2122]  eta: 0:11:27  lr: 0.001000  loss: 0.2624 (0.3772)  loss_classifier: 0.0527 (0.0872)  loss_box_reg: 0.0010 (0.0127)  loss_mask: 0.2045 (0.1580)  loss_objectness: 0.0191 (0.1156)  loss_rpn_box_reg: 0.0020 (0.0037)  time: 0.4784  data: 0.3072  max mem: 1819\n",
      "Epoch: [0]  [ 700/2122]  eta: 0:11:22  lr: 0.001000  loss: 0.0169 (0.3735)  loss_classifier: 0.0114 (0.0863)  loss_box_reg: 0.0000 (0.0126)  loss_mask: 0.0000 (0.1568)  loss_objectness: 0.0056 (0.1142)  loss_rpn_box_reg: 0.0000 (0.0036)  time: 0.4729  data: 0.3028  max mem: 1819\n",
      "Epoch: [0]  [ 710/2122]  eta: 0:11:17  lr: 0.001000  loss: 0.0146 (0.3708)  loss_classifier: 0.0100 (0.0857)  loss_box_reg: 0.0000 (0.0125)  loss_mask: 0.0000 (0.1562)  loss_objectness: 0.0051 (0.1128)  loss_rpn_box_reg: 0.0000 (0.0036)  time: 0.4638  data: 0.2949  max mem: 1819\n",
      "Epoch: [0]  [ 720/2122]  eta: 0:11:12  lr: 0.001000  loss: 0.0129 (0.3672)  loss_classifier: 0.0099 (0.0848)  loss_box_reg: 0.0000 (0.0124)  loss_mask: 0.0000 (0.1549)  loss_objectness: 0.0048 (0.1115)  loss_rpn_box_reg: 0.0000 (0.0036)  time: 0.4694  data: 0.2991  max mem: 1819\n",
      "Epoch: [0]  [ 730/2122]  eta: 0:11:07  lr: 0.001000  loss: 0.0182 (0.3650)  loss_classifier: 0.0147 (0.0842)  loss_box_reg: 0.0000 (0.0123)  loss_mask: 0.0000 (0.1547)  loss_objectness: 0.0048 (0.1102)  loss_rpn_box_reg: 0.0000 (0.0036)  time: 0.4674  data: 0.2976  max mem: 1819\n",
      "Epoch: [0]  [ 740/2122]  eta: 0:11:03  lr: 0.001000  loss: 0.1067 (0.3628)  loss_classifier: 0.0290 (0.0837)  loss_box_reg: 0.0003 (0.0122)  loss_mask: 0.0546 (0.1543)  loss_objectness: 0.0172 (0.1090)  loss_rpn_box_reg: 0.0013 (0.0036)  time: 0.4870  data: 0.3117  max mem: 1819\n",
      "Epoch: [0]  [ 750/2122]  eta: 0:10:58  lr: 0.001000  loss: 0.1415 (0.3607)  loss_classifier: 0.0378 (0.0833)  loss_box_reg: 0.0003 (0.0122)  loss_mask: 0.0604 (0.1538)  loss_objectness: 0.0192 (0.1079)  loss_rpn_box_reg: 0.0025 (0.0036)  time: 0.5072  data: 0.3250  max mem: 1819\n",
      "Epoch: [0]  [ 760/2122]  eta: 0:10:54  lr: 0.001000  loss: 0.1207 (0.3576)  loss_classifier: 0.0299 (0.0826)  loss_box_reg: 0.0001 (0.0121)  loss_mask: 0.0604 (0.1528)  loss_objectness: 0.0160 (0.1066)  loss_rpn_box_reg: 0.0007 (0.0036)  time: 0.4898  data: 0.3136  max mem: 1819\n",
      "Epoch: [0]  [ 770/2122]  eta: 0:10:48  lr: 0.001000  loss: 0.0199 (0.3537)  loss_classifier: 0.0127 (0.0818)  loss_box_reg: 0.0000 (0.0119)  loss_mask: 0.0000 (0.1511)  loss_objectness: 0.0049 (0.1053)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4718  data: 0.3038  max mem: 1819\n",
      "Epoch: [0]  [ 780/2122]  eta: 0:10:43  lr: 0.001000  loss: 0.0068 (0.3500)  loss_classifier: 0.0044 (0.0811)  loss_box_reg: 0.0000 (0.0118)  loss_mask: 0.0000 (0.1495)  loss_objectness: 0.0033 (0.1041)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4577  data: 0.2925  max mem: 1819\n",
      "Epoch: [0]  [ 790/2122]  eta: 0:10:38  lr: 0.001000  loss: 0.0178 (0.3479)  loss_classifier: 0.0135 (0.0806)  loss_box_reg: 0.0000 (0.0117)  loss_mask: 0.0000 (0.1490)  loss_objectness: 0.0043 (0.1031)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4678  data: 0.2961  max mem: 1819\n",
      "Epoch: [0]  [ 800/2122]  eta: 0:10:33  lr: 0.001000  loss: 0.0922 (0.3458)  loss_classifier: 0.0471 (0.0802)  loss_box_reg: 0.0005 (0.0118)  loss_mask: 0.0224 (0.1483)  loss_objectness: 0.0156 (0.1020)  loss_rpn_box_reg: 0.0028 (0.0035)  time: 0.4742  data: 0.3015  max mem: 1819\n",
      "Epoch: [0]  [ 810/2122]  eta: 0:10:29  lr: 0.001000  loss: 0.0288 (0.3436)  loss_classifier: 0.0162 (0.0797)  loss_box_reg: 0.0000 (0.0117)  loss_mask: 0.0000 (0.1477)  loss_objectness: 0.0141 (0.1010)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4760  data: 0.3033  max mem: 1819\n",
      "Epoch: [0]  [ 820/2122]  eta: 0:10:24  lr: 0.001000  loss: 0.0288 (0.3410)  loss_classifier: 0.0168 (0.0792)  loss_box_reg: 0.0000 (0.0116)  loss_mask: 0.0000 (0.1466)  loss_objectness: 0.0141 (0.1000)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4872  data: 0.3094  max mem: 1819\n",
      "Epoch: [0]  [ 830/2122]  eta: 0:10:19  lr: 0.001000  loss: 0.1147 (0.3394)  loss_classifier: 0.0272 (0.0788)  loss_box_reg: 0.0001 (0.0116)  loss_mask: 0.0530 (0.1465)  loss_objectness: 0.0178 (0.0991)  loss_rpn_box_reg: 0.0015 (0.0035)  time: 0.4779  data: 0.3043  max mem: 1819\n",
      "Epoch: [0]  [ 840/2122]  eta: 0:10:14  lr: 0.001000  loss: 0.0223 (0.3366)  loss_classifier: 0.0154 (0.0782)  loss_box_reg: 0.0000 (0.0115)  loss_mask: 0.0000 (0.1455)  loss_objectness: 0.0069 (0.0980)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4696  data: 0.3009  max mem: 1819\n",
      "Epoch: [0]  [ 850/2122]  eta: 0:10:09  lr: 0.001000  loss: 0.0167 (0.3346)  loss_classifier: 0.0111 (0.0776)  loss_box_reg: 0.0000 (0.0115)  loss_mask: 0.0000 (0.1450)  loss_objectness: 0.0037 (0.0971)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4678  data: 0.2978  max mem: 1819\n",
      "Epoch: [0]  [ 860/2122]  eta: 0:10:04  lr: 0.001000  loss: 0.0169 (0.3322)  loss_classifier: 0.0143 (0.0772)  loss_box_reg: 0.0000 (0.0114)  loss_mask: 0.0000 (0.1440)  loss_objectness: 0.0051 (0.0962)  loss_rpn_box_reg: 0.0000 (0.0035)  time: 0.4682  data: 0.2965  max mem: 1819\n",
      "Epoch: [0]  [ 870/2122]  eta: 0:09:59  lr: 0.001000  loss: 0.0172 (0.3293)  loss_classifier: 0.0087 (0.0765)  loss_box_reg: 0.0000 (0.0113)  loss_mask: 0.0000 (0.1429)  loss_objectness: 0.0051 (0.0952)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4638  data: 0.2953  max mem: 1819\n",
      "Epoch: [0]  [ 880/2122]  eta: 0:09:54  lr: 0.001000  loss: 0.0119 (0.3265)  loss_classifier: 0.0087 (0.0760)  loss_box_reg: 0.0000 (0.0112)  loss_mask: 0.0000 (0.1416)  loss_objectness: 0.0050 (0.0943)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4648  data: 0.2973  max mem: 1819\n",
      "Epoch: [0]  [ 890/2122]  eta: 0:09:49  lr: 0.001000  loss: 0.0184 (0.3245)  loss_classifier: 0.0147 (0.0755)  loss_box_reg: 0.0000 (0.0112)  loss_mask: 0.0000 (0.1410)  loss_objectness: 0.0037 (0.0934)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4664  data: 0.2928  max mem: 1819\n",
      "Epoch: [0]  [ 900/2122]  eta: 0:09:45  lr: 0.001000  loss: 0.0206 (0.3228)  loss_classifier: 0.0163 (0.0751)  loss_box_reg: 0.0000 (0.0112)  loss_mask: 0.0000 (0.1405)  loss_objectness: 0.0044 (0.0926)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4746  data: 0.2937  max mem: 1819\n",
      "Epoch: [0]  [ 910/2122]  eta: 0:09:40  lr: 0.001000  loss: 0.1342 (0.3213)  loss_classifier: 0.0393 (0.0748)  loss_box_reg: 0.0001 (0.0111)  loss_mask: 0.0609 (0.1402)  loss_objectness: 0.0193 (0.0918)  loss_rpn_box_reg: 0.0013 (0.0034)  time: 0.4883  data: 0.3095  max mem: 1819\n",
      "Epoch: [0]  [ 920/2122]  eta: 0:09:35  lr: 0.001000  loss: 0.0166 (0.3206)  loss_classifier: 0.0123 (0.0747)  loss_box_reg: 0.0000 (0.0112)  loss_mask: 0.0000 (0.1402)  loss_objectness: 0.0046 (0.0911)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4805  data: 0.3065  max mem: 1819\n",
      "Epoch: [0]  [ 930/2122]  eta: 0:09:30  lr: 0.001000  loss: 0.0234 (0.3187)  loss_classifier: 0.0160 (0.0743)  loss_box_reg: 0.0000 (0.0111)  loss_mask: 0.0000 (0.1396)  loss_objectness: 0.0074 (0.0903)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4700  data: 0.2998  max mem: 1819\n",
      "Epoch: [0]  [ 940/2122]  eta: 0:09:25  lr: 0.001000  loss: 0.0201 (0.3166)  loss_classifier: 0.0141 (0.0739)  loss_box_reg: 0.0000 (0.0111)  loss_mask: 0.0000 (0.1387)  loss_objectness: 0.0065 (0.0895)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4650  data: 0.2964  max mem: 1819\n",
      "Epoch: [0]  [ 950/2122]  eta: 0:09:20  lr: 0.001000  loss: 0.0101 (0.3142)  loss_classifier: 0.0086 (0.0735)  loss_box_reg: 0.0000 (0.0110)  loss_mask: 0.0000 (0.1376)  loss_objectness: 0.0030 (0.0887)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4756  data: 0.3055  max mem: 1819\n",
      "Epoch: [0]  [ 960/2122]  eta: 0:09:15  lr: 0.001000  loss: 0.0136 (0.3136)  loss_classifier: 0.0113 (0.0733)  loss_box_reg: 0.0000 (0.0110)  loss_mask: 0.0000 (0.1379)  loss_objectness: 0.0034 (0.0881)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4754  data: 0.3060  max mem: 1819\n",
      "Epoch: [0]  [ 970/2122]  eta: 0:09:11  lr: 0.001000  loss: 0.1594 (0.3120)  loss_classifier: 0.0384 (0.0729)  loss_box_reg: 0.0004 (0.0110)  loss_mask: 0.0724 (0.1375)  loss_objectness: 0.0134 (0.0873)  loss_rpn_box_reg: 0.0005 (0.0034)  time: 0.4717  data: 0.2994  max mem: 1819\n",
      "Epoch: [0]  [ 980/2122]  eta: 0:09:06  lr: 0.001000  loss: 0.0113 (0.3094)  loss_classifier: 0.0060 (0.0722)  loss_box_reg: 0.0000 (0.0108)  loss_mask: 0.0000 (0.1364)  loss_objectness: 0.0062 (0.0865)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4721  data: 0.3026  max mem: 1819\n",
      "Epoch: [0]  [ 990/2122]  eta: 0:09:01  lr: 0.001000  loss: 0.0048 (0.3071)  loss_classifier: 0.0017 (0.0717)  loss_box_reg: 0.0000 (0.0107)  loss_mask: 0.0000 (0.1356)  loss_objectness: 0.0029 (0.0857)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4573  data: 0.2916  max mem: 1819\n",
      "Epoch: [0]  [1000/2122]  eta: 0:08:56  lr: 0.001000  loss: 0.0048 (0.3059)  loss_classifier: 0.0018 (0.0714)  loss_box_reg: 0.0000 (0.0107)  loss_mask: 0.0000 (0.1353)  loss_objectness: 0.0029 (0.0851)  loss_rpn_box_reg: 0.0000 (0.0034)  time: 0.4643  data: 0.2985  max mem: 1819\n",
      "Epoch: [0]  [1010/2122]  eta: 0:08:51  lr: 0.001000  loss: 0.0207 (0.3041)  loss_classifier: 0.0134 (0.0710)  loss_box_reg: 0.0000 (0.0107)  loss_mask: 0.0000 (0.1348)  loss_objectness: 0.0074 (0.0844)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4675  data: 0.3004  max mem: 1819\n",
      "Epoch: [0]  [1020/2122]  eta: 0:08:46  lr: 0.001000  loss: 0.0207 (0.3023)  loss_classifier: 0.0134 (0.0706)  loss_box_reg: 0.0000 (0.0106)  loss_mask: 0.0000 (0.1341)  loss_objectness: 0.0073 (0.0837)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4631  data: 0.2927  max mem: 1819\n",
      "Epoch: [0]  [1030/2122]  eta: 0:08:41  lr: 0.001000  loss: 0.0539 (0.3012)  loss_classifier: 0.0191 (0.0703)  loss_box_reg: 0.0001 (0.0106)  loss_mask: 0.0226 (0.1340)  loss_objectness: 0.0098 (0.0831)  loss_rpn_box_reg: 0.0009 (0.0033)  time: 0.4800  data: 0.3074  max mem: 1819\n",
      "Epoch: [0]  [1040/2122]  eta: 0:08:37  lr: 0.001000  loss: 0.0875 (0.2990)  loss_classifier: 0.0207 (0.0698)  loss_box_reg: 0.0001 (0.0105)  loss_mask: 0.0367 (0.1329)  loss_objectness: 0.0118 (0.0824)  loss_rpn_box_reg: 0.0009 (0.0033)  time: 0.4930  data: 0.3197  max mem: 1819\n",
      "Epoch: [0]  [1050/2122]  eta: 0:08:32  lr: 0.001000  loss: 0.0108 (0.2971)  loss_classifier: 0.0074 (0.0693)  loss_box_reg: 0.0000 (0.0104)  loss_mask: 0.0000 (0.1324)  loss_objectness: 0.0033 (0.0817)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4681  data: 0.3004  max mem: 1819\n",
      "Epoch: [0]  [1060/2122]  eta: 0:08:26  lr: 0.001000  loss: 0.0121 (0.2954)  loss_classifier: 0.0064 (0.0690)  loss_box_reg: 0.0000 (0.0104)  loss_mask: 0.0000 (0.1316)  loss_objectness: 0.0041 (0.0811)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4421  data: 0.2792  max mem: 1819\n",
      "Epoch: [0]  [1070/2122]  eta: 0:08:22  lr: 0.001000  loss: 0.0173 (0.2941)  loss_classifier: 0.0132 (0.0688)  loss_box_reg: 0.0000 (0.0103)  loss_mask: 0.0000 (0.1311)  loss_objectness: 0.0064 (0.0806)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4549  data: 0.2896  max mem: 1819\n",
      "Epoch: [0]  [1080/2122]  eta: 0:08:17  lr: 0.001000  loss: 0.0178 (0.2921)  loss_classifier: 0.0133 (0.0684)  loss_box_reg: 0.0000 (0.0102)  loss_mask: 0.0000 (0.1301)  loss_objectness: 0.0064 (0.0800)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4796  data: 0.3067  max mem: 1819\n",
      "Epoch: [0]  [1090/2122]  eta: 0:08:12  lr: 0.001000  loss: 0.0579 (0.2914)  loss_classifier: 0.0218 (0.0681)  loss_box_reg: 0.0002 (0.0102)  loss_mask: 0.0156 (0.1304)  loss_objectness: 0.0149 (0.0794)  loss_rpn_box_reg: 0.0024 (0.0033)  time: 0.4967  data: 0.3169  max mem: 1819\n",
      "Epoch: [0]  [1100/2122]  eta: 0:08:08  lr: 0.001000  loss: 0.1460 (0.2904)  loss_classifier: 0.0307 (0.0678)  loss_box_reg: 0.0005 (0.0101)  loss_mask: 0.0814 (0.1302)  loss_objectness: 0.0187 (0.0789)  loss_rpn_box_reg: 0.0030 (0.0033)  time: 0.4859  data: 0.3107  max mem: 1819\n",
      "Epoch: [0]  [1110/2122]  eta: 0:08:03  lr: 0.001000  loss: 0.0150 (0.2889)  loss_classifier: 0.0086 (0.0674)  loss_box_reg: 0.0000 (0.0101)  loss_mask: 0.0000 (0.1298)  loss_objectness: 0.0064 (0.0783)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4701  data: 0.2971  max mem: 1819\n",
      "Epoch: [0]  [1120/2122]  eta: 0:07:58  lr: 0.001000  loss: 0.0130 (0.2880)  loss_classifier: 0.0083 (0.0672)  loss_box_reg: 0.0000 (0.0101)  loss_mask: 0.0000 (0.1297)  loss_objectness: 0.0060 (0.0778)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4656  data: 0.2955  max mem: 1819\n",
      "Epoch: [0]  [1130/2122]  eta: 0:07:53  lr: 0.001000  loss: 0.1358 (0.2877)  loss_classifier: 0.0342 (0.0670)  loss_box_reg: 0.0001 (0.0102)  loss_mask: 0.0756 (0.1299)  loss_objectness: 0.0188 (0.0772)  loss_rpn_box_reg: 0.0012 (0.0033)  time: 0.4684  data: 0.2953  max mem: 1819\n",
      "Epoch: [0]  [1140/2122]  eta: 0:07:48  lr: 0.001000  loss: 0.0233 (0.2863)  loss_classifier: 0.0182 (0.0667)  loss_box_reg: 0.0000 (0.0102)  loss_mask: 0.0000 (0.1294)  loss_objectness: 0.0081 (0.0767)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4520  data: 0.2788  max mem: 1819\n",
      "Epoch: [0]  [1150/2122]  eta: 0:07:43  lr: 0.001000  loss: 0.1269 (0.2856)  loss_classifier: 0.0236 (0.0666)  loss_box_reg: 0.0001 (0.0102)  loss_mask: 0.0754 (0.1292)  loss_objectness: 0.0113 (0.0762)  loss_rpn_box_reg: 0.0012 (0.0033)  time: 0.4562  data: 0.2860  max mem: 1819\n",
      "Epoch: [0]  [1160/2122]  eta: 0:07:38  lr: 0.001000  loss: 0.1106 (0.2837)  loss_classifier: 0.0231 (0.0662)  loss_box_reg: 0.0001 (0.0101)  loss_mask: 0.0563 (0.1284)  loss_objectness: 0.0160 (0.0757)  loss_rpn_box_reg: 0.0016 (0.0033)  time: 0.4857  data: 0.3093  max mem: 1819\n",
      "Epoch: [0]  [1170/2122]  eta: 0:07:34  lr: 0.001000  loss: 0.0229 (0.2825)  loss_classifier: 0.0112 (0.0658)  loss_box_reg: 0.0000 (0.0101)  loss_mask: 0.0000 (0.1281)  loss_objectness: 0.0105 (0.0752)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4799  data: 0.3085  max mem: 1819\n",
      "Epoch: [0]  [1180/2122]  eta: 0:07:29  lr: 0.001000  loss: 0.0103 (0.2812)  loss_classifier: 0.0073 (0.0655)  loss_box_reg: 0.0000 (0.0101)  loss_mask: 0.0000 (0.1278)  loss_objectness: 0.0034 (0.0746)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4721  data: 0.3024  max mem: 1819\n",
      "Epoch: [0]  [1190/2122]  eta: 0:07:24  lr: 0.001000  loss: 0.0103 (0.2801)  loss_classifier: 0.0073 (0.0651)  loss_box_reg: 0.0000 (0.0100)  loss_mask: 0.0000 (0.1276)  loss_objectness: 0.0029 (0.0741)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4762  data: 0.3039  max mem: 1819\n",
      "Epoch: [0]  [1200/2122]  eta: 0:07:19  lr: 0.001000  loss: 0.0150 (0.2792)  loss_classifier: 0.0125 (0.0649)  loss_box_reg: 0.0000 (0.0100)  loss_mask: 0.0000 (0.1275)  loss_objectness: 0.0037 (0.0736)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4737  data: 0.3033  max mem: 1819\n",
      "Epoch: [0]  [1210/2122]  eta: 0:07:15  lr: 0.001000  loss: 0.1631 (0.2789)  loss_classifier: 0.0283 (0.0646)  loss_box_reg: 0.0002 (0.0100)  loss_mask: 0.0847 (0.1279)  loss_objectness: 0.0143 (0.0731)  loss_rpn_box_reg: 0.0012 (0.0033)  time: 0.4899  data: 0.3105  max mem: 1819\n",
      "Epoch: [0]  [1220/2122]  eta: 0:07:10  lr: 0.001000  loss: 0.1234 (0.2776)  loss_classifier: 0.0283 (0.0644)  loss_box_reg: 0.0001 (0.0099)  loss_mask: 0.0846 (0.1274)  loss_objectness: 0.0120 (0.0727)  loss_rpn_box_reg: 0.0013 (0.0033)  time: 0.5008  data: 0.3191  max mem: 1819\n",
      "Epoch: [0]  [1230/2122]  eta: 0:07:05  lr: 0.001000  loss: 0.0191 (0.2767)  loss_classifier: 0.0119 (0.0641)  loss_box_reg: 0.0000 (0.0099)  loss_mask: 0.0000 (0.1272)  loss_objectness: 0.0088 (0.0722)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4837  data: 0.3081  max mem: 1819\n",
      "Epoch: [0]  [1240/2122]  eta: 0:07:00  lr: 0.001000  loss: 0.1015 (0.2759)  loss_classifier: 0.0252 (0.0638)  loss_box_reg: 0.0000 (0.0099)  loss_mask: 0.0537 (0.1270)  loss_objectness: 0.0108 (0.0718)  loss_rpn_box_reg: 0.0010 (0.0033)  time: 0.4729  data: 0.2985  max mem: 1819\n",
      "Epoch: [0]  [1250/2122]  eta: 0:06:56  lr: 0.001000  loss: 0.0079 (0.2745)  loss_classifier: 0.0062 (0.0635)  loss_box_reg: 0.0000 (0.0099)  loss_mask: 0.0000 (0.1265)  loss_objectness: 0.0041 (0.0713)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4786  data: 0.3078  max mem: 1819\n",
      "Epoch: [0]  [1260/2122]  eta: 0:06:51  lr: 0.001000  loss: 0.0164 (0.2735)  loss_classifier: 0.0106 (0.0633)  loss_box_reg: 0.0000 (0.0098)  loss_mask: 0.0000 (0.1262)  loss_objectness: 0.0057 (0.0709)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4818  data: 0.3080  max mem: 1819\n",
      "Epoch: [0]  [1270/2122]  eta: 0:06:46  lr: 0.001000  loss: 0.0164 (0.2724)  loss_classifier: 0.0102 (0.0630)  loss_box_reg: 0.0000 (0.0098)  loss_mask: 0.0000 (0.1259)  loss_objectness: 0.0057 (0.0704)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4760  data: 0.3044  max mem: 1819\n",
      "Epoch: [0]  [1280/2122]  eta: 0:06:41  lr: 0.001000  loss: 0.0119 (0.2721)  loss_classifier: 0.0067 (0.0627)  loss_box_reg: 0.0000 (0.0098)  loss_mask: 0.0000 (0.1264)  loss_objectness: 0.0052 (0.0700)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4754  data: 0.3090  max mem: 1819\n",
      "Epoch: [0]  [1290/2122]  eta: 0:06:36  lr: 0.001000  loss: 0.0091 (0.2706)  loss_classifier: 0.0061 (0.0623)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1258)  loss_objectness: 0.0034 (0.0695)  loss_rpn_box_reg: 0.0000 (0.0033)  time: 0.4680  data: 0.2981  max mem: 1819\n",
      "Epoch: [0]  [1300/2122]  eta: 0:06:32  lr: 0.001000  loss: 0.0060 (0.2697)  loss_classifier: 0.0031 (0.0621)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1256)  loss_objectness: 0.0030 (0.0691)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4704  data: 0.3007  max mem: 1819\n",
      "Epoch: [0]  [1310/2122]  eta: 0:06:27  lr: 0.001000  loss: 0.0167 (0.2691)  loss_classifier: 0.0094 (0.0618)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1257)  loss_objectness: 0.0072 (0.0687)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4813  data: 0.3104  max mem: 1819\n",
      "Epoch: [0]  [1320/2122]  eta: 0:06:22  lr: 0.001000  loss: 0.1275 (0.2686)  loss_classifier: 0.0266 (0.0616)  loss_box_reg: 0.0002 (0.0097)  loss_mask: 0.0705 (0.1257)  loss_objectness: 0.0101 (0.0684)  loss_rpn_box_reg: 0.0005 (0.0032)  time: 0.4735  data: 0.3010  max mem: 1819\n",
      "Epoch: [0]  [1330/2122]  eta: 0:06:17  lr: 0.001000  loss: 0.0221 (0.2680)  loss_classifier: 0.0132 (0.0613)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1258)  loss_objectness: 0.0091 (0.0680)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4737  data: 0.3010  max mem: 1819\n",
      "Epoch: [0]  [1340/2122]  eta: 0:06:13  lr: 0.001000  loss: 0.0221 (0.2674)  loss_classifier: 0.0132 (0.0611)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1258)  loss_objectness: 0.0091 (0.0676)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4737  data: 0.3012  max mem: 1819\n",
      "Epoch: [0]  [1350/2122]  eta: 0:06:08  lr: 0.001000  loss: 0.1254 (0.2673)  loss_classifier: 0.0255 (0.0609)  loss_box_reg: 0.0002 (0.0097)  loss_mask: 0.0918 (0.1263)  loss_objectness: 0.0149 (0.0672)  loss_rpn_box_reg: 0.0014 (0.0032)  time: 0.4776  data: 0.3044  max mem: 1819\n",
      "Epoch: [0]  [1360/2122]  eta: 0:06:03  lr: 0.001000  loss: 0.1835 (0.2667)  loss_classifier: 0.0382 (0.0608)  loss_box_reg: 0.0004 (0.0096)  loss_mask: 0.0982 (0.1261)  loss_objectness: 0.0182 (0.0669)  loss_rpn_box_reg: 0.0016 (0.0032)  time: 0.4977  data: 0.3163  max mem: 1819\n",
      "Epoch: [0]  [1370/2122]  eta: 0:05:59  lr: 0.001000  loss: 0.1966 (0.2664)  loss_classifier: 0.0389 (0.0607)  loss_box_reg: 0.0003 (0.0096)  loss_mask: 0.0902 (0.1262)  loss_objectness: 0.0194 (0.0666)  loss_rpn_box_reg: 0.0012 (0.0032)  time: 0.5062  data: 0.3259  max mem: 1819\n",
      "Epoch: [0]  [1380/2122]  eta: 0:05:54  lr: 0.001000  loss: 0.1088 (0.2652)  loss_classifier: 0.0246 (0.0604)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0618 (0.1258)  loss_objectness: 0.0158 (0.0662)  loss_rpn_box_reg: 0.0012 (0.0032)  time: 0.5016  data: 0.3271  max mem: 1819\n",
      "Epoch: [0]  [1390/2122]  eta: 0:05:49  lr: 0.001000  loss: 0.0364 (0.2648)  loss_classifier: 0.0246 (0.0603)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0000 (0.1258)  loss_objectness: 0.0089 (0.0659)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4897  data: 0.3119  max mem: 1819\n",
      "Epoch: [0]  [1400/2122]  eta: 0:05:44  lr: 0.001000  loss: 0.0165 (0.2636)  loss_classifier: 0.0109 (0.0601)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0000 (0.1252)  loss_objectness: 0.0056 (0.0655)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4671  data: 0.2944  max mem: 1819\n",
      "Epoch: [0]  [1410/2122]  eta: 0:05:40  lr: 0.001000  loss: 0.1490 (0.2634)  loss_classifier: 0.0232 (0.0599)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0586 (0.1255)  loss_objectness: 0.0131 (0.0652)  loss_rpn_box_reg: 0.0003 (0.0032)  time: 0.4722  data: 0.3015  max mem: 1819\n",
      "Epoch: [0]  [1420/2122]  eta: 0:05:35  lr: 0.001000  loss: 0.1565 (0.2637)  loss_classifier: 0.0364 (0.0599)  loss_box_reg: 0.0009 (0.0097)  loss_mask: 0.1038 (0.1260)  loss_objectness: 0.0162 (0.0648)  loss_rpn_box_reg: 0.0023 (0.0032)  time: 0.4918  data: 0.3145  max mem: 1819\n",
      "Epoch: [0]  [1430/2122]  eta: 0:05:30  lr: 0.001000  loss: 0.1957 (0.2629)  loss_classifier: 0.0402 (0.0598)  loss_box_reg: 0.0008 (0.0097)  loss_mask: 0.0973 (0.1258)  loss_objectness: 0.0154 (0.0645)  loss_rpn_box_reg: 0.0021 (0.0032)  time: 0.4851  data: 0.3080  max mem: 1819\n",
      "Epoch: [0]  [1440/2122]  eta: 0:05:25  lr: 0.001000  loss: 0.1574 (0.2625)  loss_classifier: 0.0384 (0.0596)  loss_box_reg: 0.0003 (0.0097)  loss_mask: 0.0722 (0.1258)  loss_objectness: 0.0097 (0.0642)  loss_rpn_box_reg: 0.0007 (0.0032)  time: 0.4805  data: 0.3034  max mem: 1819\n",
      "Epoch: [0]  [1450/2122]  eta: 0:05:21  lr: 0.001000  loss: 0.0245 (0.2619)  loss_classifier: 0.0203 (0.0595)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1256)  loss_objectness: 0.0066 (0.0638)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4799  data: 0.3016  max mem: 1819\n",
      "Epoch: [0]  [1460/2122]  eta: 0:05:16  lr: 0.001000  loss: 0.0117 (0.2612)  loss_classifier: 0.0091 (0.0593)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1256)  loss_objectness: 0.0049 (0.0635)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4734  data: 0.2977  max mem: 1819\n",
      "Epoch: [0]  [1470/2122]  eta: 0:05:11  lr: 0.001000  loss: 0.0137 (0.2608)  loss_classifier: 0.0122 (0.0592)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1256)  loss_objectness: 0.0040 (0.0632)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4889  data: 0.3143  max mem: 1819\n",
      "Epoch: [0]  [1480/2122]  eta: 0:05:06  lr: 0.001000  loss: 0.1452 (0.2606)  loss_classifier: 0.0353 (0.0593)  loss_box_reg: 0.0001 (0.0097)  loss_mask: 0.0869 (0.1255)  loss_objectness: 0.0183 (0.0629)  loss_rpn_box_reg: 0.0021 (0.0032)  time: 0.4998  data: 0.3235  max mem: 1819\n",
      "Epoch: [0]  [1490/2122]  eta: 0:05:02  lr: 0.001000  loss: 0.1853 (0.2607)  loss_classifier: 0.0408 (0.0592)  loss_box_reg: 0.0001 (0.0098)  loss_mask: 0.0876 (0.1260)  loss_objectness: 0.0160 (0.0626)  loss_rpn_box_reg: 0.0013 (0.0032)  time: 0.4788  data: 0.3059  max mem: 1819\n",
      "Epoch: [0]  [1500/2122]  eta: 0:04:57  lr: 0.001000  loss: 0.0208 (0.2601)  loss_classifier: 0.0144 (0.0591)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1257)  loss_objectness: 0.0066 (0.0623)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4773  data: 0.3058  max mem: 1819\n",
      "Epoch: [0]  [1510/2122]  eta: 0:04:52  lr: 0.001000  loss: 0.0201 (0.2596)  loss_classifier: 0.0150 (0.0590)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1257)  loss_objectness: 0.0058 (0.0620)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4694  data: 0.2986  max mem: 1819\n",
      "Epoch: [0]  [1520/2122]  eta: 0:04:47  lr: 0.001000  loss: 0.1985 (0.2600)  loss_classifier: 0.0393 (0.0589)  loss_box_reg: 0.0001 (0.0097)  loss_mask: 0.1136 (0.1265)  loss_objectness: 0.0181 (0.0618)  loss_rpn_box_reg: 0.0018 (0.0032)  time: 0.4782  data: 0.3020  max mem: 1819\n",
      "Epoch: [0]  [1530/2122]  eta: 0:04:42  lr: 0.001000  loss: 0.0145 (0.2589)  loss_classifier: 0.0091 (0.0586)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1260)  loss_objectness: 0.0054 (0.0614)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4784  data: 0.3040  max mem: 1819\n",
      "Epoch: [0]  [1540/2122]  eta: 0:04:38  lr: 0.001000  loss: 0.0084 (0.2586)  loss_classifier: 0.0065 (0.0585)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1261)  loss_objectness: 0.0033 (0.0611)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4637  data: 0.2918  max mem: 1819\n",
      "Epoch: [0]  [1550/2122]  eta: 0:04:33  lr: 0.001000  loss: 0.0281 (0.2581)  loss_classifier: 0.0196 (0.0582)  loss_box_reg: 0.0000 (0.0097)  loss_mask: 0.0000 (0.1262)  loss_objectness: 0.0085 (0.0608)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4725  data: 0.2986  max mem: 1819\n",
      "Epoch: [0]  [1560/2122]  eta: 0:04:28  lr: 0.001000  loss: 0.0157 (0.2571)  loss_classifier: 0.0113 (0.0581)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0000 (0.1257)  loss_objectness: 0.0057 (0.0605)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4864  data: 0.3142  max mem: 1819\n",
      "Epoch: [0]  [1570/2122]  eta: 0:04:23  lr: 0.001000  loss: 0.0157 (0.2562)  loss_classifier: 0.0113 (0.0579)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0000 (0.1254)  loss_objectness: 0.0057 (0.0602)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4909  data: 0.3194  max mem: 1819\n",
      "Epoch: [0]  [1580/2122]  eta: 0:04:19  lr: 0.001000  loss: 0.0089 (0.2549)  loss_classifier: 0.0065 (0.0576)  loss_box_reg: 0.0000 (0.0096)  loss_mask: 0.0000 (0.1247)  loss_objectness: 0.0029 (0.0599)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4780  data: 0.3048  max mem: 1819\n",
      "Epoch: [0]  [1590/2122]  eta: 0:04:14  lr: 0.001000  loss: 0.0096 (0.2540)  loss_classifier: 0.0073 (0.0574)  loss_box_reg: 0.0000 (0.0095)  loss_mask: 0.0000 (0.1243)  loss_objectness: 0.0033 (0.0596)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4752  data: 0.3006  max mem: 1819\n",
      "Epoch: [0]  [1600/2122]  eta: 0:04:09  lr: 0.001000  loss: 0.0105 (0.2535)  loss_classifier: 0.0083 (0.0573)  loss_box_reg: 0.0000 (0.0095)  loss_mask: 0.0000 (0.1242)  loss_objectness: 0.0039 (0.0594)  loss_rpn_box_reg: 0.0000 (0.0032)  time: 0.4669  data: 0.2983  max mem: 1819\n",
      "Epoch: [0]  [1610/2122]  eta: 0:04:04  lr: 0.001000  loss: 0.1348 (0.2531)  loss_classifier: 0.0256 (0.0572)  loss_box_reg: 0.0004 (0.0095)  loss_mask: 0.0641 (0.1240)  loss_objectness: 0.0137 (0.0592)  loss_rpn_box_reg: 0.0027 (0.0032)  time: 0.4800  data: 0.3028  max mem: 1819\n",
      "Epoch: [0]  [1620/2122]  eta: 0:03:59  lr: 0.001000  loss: 0.1348 (0.2527)  loss_classifier: 0.0361 (0.0571)  loss_box_reg: 0.0004 (0.0095)  loss_mask: 0.0725 (0.1241)  loss_objectness: 0.0120 (0.0589)  loss_rpn_box_reg: 0.0016 (0.0031)  time: 0.4882  data: 0.3080  max mem: 1819\n",
      "Epoch: [0]  [1630/2122]  eta: 0:03:55  lr: 0.001000  loss: 0.0989 (0.2523)  loss_classifier: 0.0243 (0.0570)  loss_box_reg: 0.0001 (0.0094)  loss_mask: 0.0587 (0.1240)  loss_objectness: 0.0091 (0.0586)  loss_rpn_box_reg: 0.0004 (0.0032)  time: 0.4851  data: 0.3070  max mem: 1819\n",
      "Epoch: [0]  [1640/2122]  eta: 0:03:50  lr: 0.001000  loss: 0.1108 (0.2516)  loss_classifier: 0.0252 (0.0568)  loss_box_reg: 0.0002 (0.0094)  loss_mask: 0.0587 (0.1239)  loss_objectness: 0.0136 (0.0584)  loss_rpn_box_reg: 0.0012 (0.0032)  time: 0.4828  data: 0.3045  max mem: 1819\n",
      "Epoch: [0]  [1650/2122]  eta: 0:03:45  lr: 0.001000  loss: 0.1108 (0.2511)  loss_classifier: 0.0245 (0.0567)  loss_box_reg: 0.0001 (0.0094)  loss_mask: 0.0572 (0.1238)  loss_objectness: 0.0132 (0.0581)  loss_rpn_box_reg: 0.0004 (0.0032)  time: 0.4717  data: 0.3025  max mem: 1819\n",
      "Epoch: [0]  [1660/2122]  eta: 0:03:40  lr: 0.001000  loss: 0.0153 (0.2506)  loss_classifier: 0.0102 (0.0565)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1237)  loss_objectness: 0.0051 (0.0579)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4742  data: 0.3039  max mem: 1819\n",
      "Epoch: [0]  [1670/2122]  eta: 0:03:36  lr: 0.001000  loss: 0.0255 (0.2497)  loss_classifier: 0.0197 (0.0563)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1232)  loss_objectness: 0.0051 (0.0576)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4710  data: 0.2977  max mem: 1819\n",
      "Epoch: [0]  [1680/2122]  eta: 0:03:31  lr: 0.001000  loss: 0.0199 (0.2490)  loss_classifier: 0.0147 (0.0562)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1229)  loss_objectness: 0.0068 (0.0574)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4734  data: 0.3024  max mem: 1819\n",
      "Epoch: [0]  [1690/2122]  eta: 0:03:26  lr: 0.001000  loss: 0.0199 (0.2487)  loss_classifier: 0.0126 (0.0562)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1228)  loss_objectness: 0.0088 (0.0572)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4874  data: 0.3133  max mem: 1819\n",
      "Epoch: [0]  [1700/2122]  eta: 0:03:21  lr: 0.001000  loss: 0.0853 (0.2482)  loss_classifier: 0.0166 (0.0561)  loss_box_reg: 0.0001 (0.0094)  loss_mask: 0.0573 (0.1227)  loss_objectness: 0.0089 (0.0569)  loss_rpn_box_reg: 0.0007 (0.0031)  time: 0.4699  data: 0.2952  max mem: 1819\n",
      "Epoch: [0]  [1710/2122]  eta: 0:03:16  lr: 0.001000  loss: 0.0136 (0.2479)  loss_classifier: 0.0105 (0.0559)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1229)  loss_objectness: 0.0048 (0.0567)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4492  data: 0.2812  max mem: 1819\n",
      "Epoch: [0]  [1720/2122]  eta: 0:03:12  lr: 0.001000  loss: 0.0136 (0.2476)  loss_classifier: 0.0105 (0.0558)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1228)  loss_objectness: 0.0031 (0.0564)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4607  data: 0.2890  max mem: 1819\n",
      "Epoch: [0]  [1730/2122]  eta: 0:03:07  lr: 0.001000  loss: 0.0230 (0.2472)  loss_classifier: 0.0161 (0.0557)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1228)  loss_objectness: 0.0060 (0.0562)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4588  data: 0.2880  max mem: 1819\n",
      "Epoch: [0]  [1740/2122]  eta: 0:03:02  lr: 0.001000  loss: 0.0238 (0.2467)  loss_classifier: 0.0179 (0.0556)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1227)  loss_objectness: 0.0061 (0.0560)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4748  data: 0.3030  max mem: 1819\n",
      "Epoch: [0]  [1750/2122]  eta: 0:02:57  lr: 0.001000  loss: 0.0238 (0.2466)  loss_classifier: 0.0179 (0.0555)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1229)  loss_objectness: 0.0075 (0.0557)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4925  data: 0.3143  max mem: 1819\n",
      "Epoch: [0]  [1760/2122]  eta: 0:02:52  lr: 0.001000  loss: 0.1449 (0.2468)  loss_classifier: 0.0225 (0.0554)  loss_box_reg: 0.0002 (0.0094)  loss_mask: 0.1038 (0.1233)  loss_objectness: 0.0089 (0.0555)  loss_rpn_box_reg: 0.0010 (0.0031)  time: 0.4900  data: 0.3172  max mem: 1819\n",
      "Epoch: [0]  [1770/2122]  eta: 0:02:48  lr: 0.001000  loss: 0.0178 (0.2462)  loss_classifier: 0.0121 (0.0552)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1232)  loss_objectness: 0.0057 (0.0553)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4857  data: 0.3129  max mem: 1819\n",
      "Epoch: [0]  [1780/2122]  eta: 0:02:43  lr: 0.001000  loss: 0.0133 (0.2454)  loss_classifier: 0.0107 (0.0551)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1228)  loss_objectness: 0.0030 (0.0550)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4737  data: 0.2966  max mem: 1819\n",
      "Epoch: [0]  [1790/2122]  eta: 0:02:38  lr: 0.001000  loss: 0.0122 (0.2448)  loss_classifier: 0.0091 (0.0549)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1226)  loss_objectness: 0.0024 (0.0548)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4638  data: 0.2904  max mem: 1819\n",
      "Epoch: [0]  [1800/2122]  eta: 0:02:33  lr: 0.001000  loss: 0.0195 (0.2454)  loss_classifier: 0.0163 (0.0550)  loss_box_reg: 0.0000 (0.0095)  loss_mask: 0.0000 (0.1232)  loss_objectness: 0.0054 (0.0546)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4728  data: 0.3009  max mem: 1819\n",
      "Epoch: [0]  [1810/2122]  eta: 0:02:29  lr: 0.001000  loss: 0.0291 (0.2448)  loss_classifier: 0.0243 (0.0549)  loss_box_reg: 0.0000 (0.0095)  loss_mask: 0.0000 (0.1229)  loss_objectness: 0.0095 (0.0544)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4853  data: 0.3092  max mem: 1819\n",
      "Epoch: [0]  [1820/2122]  eta: 0:02:24  lr: 0.001000  loss: 0.0291 (0.2443)  loss_classifier: 0.0243 (0.0547)  loss_box_reg: 0.0000 (0.0095)  loss_mask: 0.0000 (0.1228)  loss_objectness: 0.0077 (0.0542)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4760  data: 0.3004  max mem: 1819\n",
      "Epoch: [0]  [1830/2122]  eta: 0:02:19  lr: 0.001000  loss: 0.1614 (0.2438)  loss_classifier: 0.0283 (0.0546)  loss_box_reg: 0.0003 (0.0095)  loss_mask: 0.0888 (0.1227)  loss_objectness: 0.0077 (0.0539)  loss_rpn_box_reg: 0.0007 (0.0031)  time: 0.4826  data: 0.3068  max mem: 1819\n",
      "Epoch: [0]  [1840/2122]  eta: 0:02:14  lr: 0.001000  loss: 0.0210 (0.2431)  loss_classifier: 0.0163 (0.0545)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1224)  loss_objectness: 0.0051 (0.0537)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4915  data: 0.3138  max mem: 1819\n",
      "Epoch: [0]  [1850/2122]  eta: 0:02:09  lr: 0.001000  loss: 0.0210 (0.2427)  loss_classifier: 0.0149 (0.0544)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1223)  loss_objectness: 0.0045 (0.0535)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4679  data: 0.2974  max mem: 1819\n",
      "Epoch: [0]  [1860/2122]  eta: 0:02:05  lr: 0.001000  loss: 0.0138 (0.2420)  loss_classifier: 0.0103 (0.0542)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1221)  loss_objectness: 0.0045 (0.0533)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4592  data: 0.2930  max mem: 1819\n",
      "Epoch: [0]  [1870/2122]  eta: 0:02:00  lr: 0.001000  loss: 0.0109 (0.2415)  loss_classifier: 0.0094 (0.0541)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1219)  loss_objectness: 0.0031 (0.0531)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4768  data: 0.3060  max mem: 1819\n",
      "Epoch: [0]  [1880/2122]  eta: 0:01:55  lr: 0.001000  loss: 0.1349 (0.2417)  loss_classifier: 0.0274 (0.0540)  loss_box_reg: 0.0003 (0.0094)  loss_mask: 0.0768 (0.1222)  loss_objectness: 0.0103 (0.0529)  loss_rpn_box_reg: 0.0016 (0.0031)  time: 0.4888  data: 0.3112  max mem: 1819\n",
      "Epoch: [0]  [1890/2122]  eta: 0:01:50  lr: 0.001000  loss: 0.0126 (0.2409)  loss_classifier: 0.0102 (0.0539)  loss_box_reg: 0.0000 (0.0094)  loss_mask: 0.0000 (0.1219)  loss_objectness: 0.0047 (0.0527)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4541  data: 0.2840  max mem: 1819\n",
      "Epoch: [0]  [1900/2122]  eta: 0:01:45  lr: 0.001000  loss: 0.0126 (0.2402)  loss_classifier: 0.0102 (0.0538)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1215)  loss_objectness: 0.0037 (0.0525)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4333  data: 0.2705  max mem: 1819\n",
      "Epoch: [0]  [1910/2122]  eta: 0:01:41  lr: 0.001000  loss: 0.0795 (0.2401)  loss_classifier: 0.0221 (0.0538)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0440 (0.1217)  loss_objectness: 0.0113 (0.0523)  loss_rpn_box_reg: 0.0006 (0.0031)  time: 0.4670  data: 0.2944  max mem: 1819\n",
      "Epoch: [0]  [1920/2122]  eta: 0:01:36  lr: 0.001000  loss: 0.0366 (0.2397)  loss_classifier: 0.0221 (0.0537)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1214)  loss_objectness: 0.0095 (0.0521)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4773  data: 0.3032  max mem: 1819\n",
      "Epoch: [0]  [1930/2122]  eta: 0:01:31  lr: 0.001000  loss: 0.0145 (0.2390)  loss_classifier: 0.0111 (0.0536)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1211)  loss_objectness: 0.0038 (0.0519)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4673  data: 0.2955  max mem: 1819\n",
      "Epoch: [0]  [1940/2122]  eta: 0:01:26  lr: 0.001000  loss: 0.0091 (0.2381)  loss_classifier: 0.0077 (0.0534)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1207)  loss_objectness: 0.0020 (0.0517)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4721  data: 0.3022  max mem: 1819\n",
      "Epoch: [0]  [1950/2122]  eta: 0:01:22  lr: 0.001000  loss: 0.0587 (0.2383)  loss_classifier: 0.0289 (0.0535)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1208)  loss_objectness: 0.0119 (0.0515)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4902  data: 0.3163  max mem: 1819\n",
      "Epoch: [0]  [1960/2122]  eta: 0:01:17  lr: 0.001000  loss: 0.1228 (0.2393)  loss_classifier: 0.0408 (0.0534)  loss_box_reg: 0.0003 (0.0093)  loss_mask: 0.0576 (0.1221)  loss_objectness: 0.0164 (0.0513)  loss_rpn_box_reg: 0.0014 (0.0031)  time: 0.4725  data: 0.2972  max mem: 1819\n",
      "Epoch: [0]  [1970/2122]  eta: 0:01:12  lr: 0.001000  loss: 0.0215 (0.2396)  loss_classifier: 0.0173 (0.0533)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1227)  loss_objectness: 0.0057 (0.0512)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4717  data: 0.2979  max mem: 1819\n",
      "Epoch: [0]  [1980/2122]  eta: 0:01:07  lr: 0.001000  loss: 0.3388 (0.2401)  loss_classifier: 0.0256 (0.0534)  loss_box_reg: 0.0001 (0.0094)  loss_mask: 0.2925 (0.1232)  loss_objectness: 0.0123 (0.0510)  loss_rpn_box_reg: 0.0015 (0.0031)  time: 0.4976  data: 0.3201  max mem: 1819\n",
      "Epoch: [0]  [1990/2122]  eta: 0:01:02  lr: 0.001000  loss: 0.2016 (0.2398)  loss_classifier: 0.0256 (0.0532)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.1510 (0.1233)  loss_objectness: 0.0123 (0.0509)  loss_rpn_box_reg: 0.0015 (0.0031)  time: 0.4840  data: 0.3077  max mem: 1819\n",
      "Epoch: [0]  [2000/2122]  eta: 0:00:58  lr: 0.001000  loss: 0.0169 (0.2393)  loss_classifier: 0.0097 (0.0531)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1231)  loss_objectness: 0.0091 (0.0507)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4621  data: 0.2882  max mem: 1819\n",
      "Epoch: [0]  [2010/2122]  eta: 0:00:53  lr: 0.001000  loss: 0.0124 (0.2391)  loss_classifier: 0.0070 (0.0530)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1233)  loss_objectness: 0.0035 (0.0505)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4525  data: 0.2805  max mem: 1819\n",
      "Epoch: [0]  [2020/2122]  eta: 0:00:48  lr: 0.001000  loss: 0.0395 (0.2389)  loss_classifier: 0.0259 (0.0530)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1231)  loss_objectness: 0.0107 (0.0504)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4659  data: 0.2943  max mem: 1819\n",
      "Epoch: [0]  [2030/2122]  eta: 0:00:43  lr: 0.001000  loss: 0.0395 (0.2385)  loss_classifier: 0.0287 (0.0529)  loss_box_reg: 0.0000 (0.0093)  loss_mask: 0.0000 (0.1230)  loss_objectness: 0.0107 (0.0502)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4731  data: 0.2990  max mem: 1819\n",
      "Epoch: [0]  [2040/2122]  eta: 0:00:39  lr: 0.001000  loss: 0.0160 (0.2376)  loss_classifier: 0.0104 (0.0528)  loss_box_reg: 0.0000 (0.0092)  loss_mask: 0.0000 (0.1225)  loss_objectness: 0.0050 (0.0500)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4566  data: 0.2867  max mem: 1819\n",
      "Epoch: [0]  [2050/2122]  eta: 0:00:34  lr: 0.001000  loss: 0.0061 (0.2370)  loss_classifier: 0.0019 (0.0527)  loss_box_reg: 0.0000 (0.0092)  loss_mask: 0.0000 (0.1223)  loss_objectness: 0.0031 (0.0498)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4557  data: 0.2911  max mem: 1819\n",
      "Epoch: [0]  [2060/2122]  eta: 0:00:29  lr: 0.001000  loss: 0.0092 (0.2366)  loss_classifier: 0.0060 (0.0526)  loss_box_reg: 0.0000 (0.0092)  loss_mask: 0.0000 (0.1221)  loss_objectness: 0.0031 (0.0497)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4635  data: 0.2965  max mem: 1819\n",
      "Epoch: [0]  [2070/2122]  eta: 0:00:24  lr: 0.001000  loss: 0.0216 (0.2360)  loss_classifier: 0.0141 (0.0525)  loss_box_reg: 0.0000 (0.0091)  loss_mask: 0.0000 (0.1217)  loss_objectness: 0.0056 (0.0496)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4658  data: 0.2953  max mem: 1819\n",
      "Epoch: [0]  [2080/2122]  eta: 0:00:20  lr: 0.001000  loss: 0.0113 (0.2355)  loss_classifier: 0.0069 (0.0524)  loss_box_reg: 0.0000 (0.0091)  loss_mask: 0.0000 (0.1216)  loss_objectness: 0.0056 (0.0494)  loss_rpn_box_reg: 0.0000 (0.0031)  time: 0.4694  data: 0.2985  max mem: 1819\n",
      "Epoch: [0]  [2090/2122]  eta: 0:00:15  lr: 0.001000  loss: 0.1017 (0.2362)  loss_classifier: 0.0284 (0.0524)  loss_box_reg: 0.0001 (0.0091)  loss_mask: 0.0507 (0.1223)  loss_objectness: 0.0152 (0.0493)  loss_rpn_box_reg: 0.0016 (0.0031)  time: 0.4809  data: 0.3069  max mem: 1819\n",
      "Epoch: [0]  [2100/2122]  eta: 0:00:10  lr: 0.001000  loss: 0.2557 (0.2362)  loss_classifier: 0.0388 (0.0523)  loss_box_reg: 0.0010 (0.0091)  loss_mask: 0.1534 (0.1224)  loss_objectness: 0.0194 (0.0491)  loss_rpn_box_reg: 0.0039 (0.0031)  time: 0.4838  data: 0.3075  max mem: 1819\n",
      "Epoch: [0]  [2110/2122]  eta: 0:00:05  lr: 0.001000  loss: 0.2140 (0.2359)  loss_classifier: 0.0347 (0.0523)  loss_box_reg: 0.0003 (0.0091)  loss_mask: 0.1146 (0.1224)  loss_objectness: 0.0171 (0.0490)  loss_rpn_box_reg: 0.0007 (0.0031)  time: 0.4725  data: 0.3016  max mem: 1819\n",
      "Epoch: [0]  [2120/2122]  eta: 0:00:00  lr: 0.001000  loss: 0.2124 (0.2359)  loss_classifier: 0.0543 (0.0523)  loss_box_reg: 0.0003 (0.0092)  loss_mask: 0.0853 (0.1224)  loss_objectness: 0.0179 (0.0489)  loss_rpn_box_reg: 0.0014 (0.0031)  time: 0.4646  data: 0.2911  max mem: 1819\n",
      "Epoch: [0]  [2121/2122]  eta: 0:00:00  lr: 0.001000  loss: 0.1578 (0.2359)  loss_classifier: 0.0401 (0.0523)  loss_box_reg: 0.0000 (0.0092)  loss_mask: 0.0853 (0.1224)  loss_objectness: 0.0151 (0.0489)  loss_rpn_box_reg: 0.0025 (0.0031)  time: 0.4638  data: 0.2902  max mem: 1819\n",
      "Epoch: [0] Total time: 0:16:51 (0.4767 s / it)\n",
      "Averaged stats: lr: 0.001000  loss: 0.1578 (0.2359)  loss_classifier: 0.0401 (0.0523)  loss_box_reg: 0.0000 (0.0092)  loss_mask: 0.0853 (0.1224)  loss_objectness: 0.0151 (0.0489)  loss_rpn_box_reg: 0.0025 (0.0031)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "train_loger = xami_train_one_epoch(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dataloader,\n",
    "    device=device,\n",
    "    epoch=0,\n",
    "    print_freq=10,\n",
    "    iou_types=iou_types,\n",
    "    coco=None,\n",
    "    score_thres=None,\n",
    "    evaluate_on_run=False,\n",
    "    params_dict=None,\n",
    "    dynamic_loss_weight=dynamic_loss_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
