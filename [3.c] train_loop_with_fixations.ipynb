{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils.print as print_f\n",
    "\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from utils.engine import xami_train_one_epoch, xami_evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_ap_ars, plot_result\n",
    "from utils.save import get_data_from_metric_logger\n",
    "from utils.coco_utils import get_cocos\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_multimodal_rcnn_model\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ap_ar, get_ap_ar_for_train_val\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from models.dynamic_loss import DynamicWeightedLoss\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS, XAMI_MIMIC_PATH\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([ 637,  603,  492,  368,  957, 1335,  401, 1119, 1530, 1277, 1973,\n",
       "        2017, 1771, 1528, 1351, 1194, 1294, 1531,  915, 1131, 1140, 1133,\n",
       "         447,  652,  509,  264, 1923, 1888, 1912, 1933, 1922, 1548, 1377,\n",
       "        1420, 1166, -106, -161, -233], dtype=int64),\n",
       " 'y': array([ 966, 1018, 1310, 1623, 1590, 1540, 1415, 1106, 1044, 1009, 1334,\n",
       "        1188, 1152, 1639,  300,  255,  154,  277,  222,  732, 1045, 1210,\n",
       "         730,  749,  196,  206, 1156,  635,  125, 1197,  369,   44,  208,\n",
       "          61,   15,  865,  818,  812], dtype=int64),\n",
       " 'dur': array([0.326, 0.162, 0.302, 0.249, 0.325, 0.289, 0.272, 0.204, 0.274,\n",
       "        0.392, 0.529, 0.17 , 0.321, 0.243, 0.081, 0.237, 0.33 , 0.51 ,\n",
       "        0.327, 0.496, 0.47 , 0.234, 0.344, 0.625, 0.37 , 0.495, 0.268,\n",
       "        0.511, 0.176, 0.345, 0.294, 0.191, 0.47 , 0.236, 0.114, 0.181,\n",
       "        0.098, 0.303]),\n",
       " 'pupil': array([0.551, 0.563, 0.632, 0.751, 0.71 , 0.692, 0.751, 0.725, 0.735,\n",
       "        0.799, 0.822, 0.827, 0.774, 0.744, 0.584, 0.553, 0.625, 0.755,\n",
       "        0.739, 0.546, 0.681, 0.789, 0.724, 0.722, 0.589, 0.703, 0.568,\n",
       "        0.615, 0.673, 0.751, 0.688, 0.755, 0.821, 0.853, 0.87 , 0.896,\n",
       "        0.894, 0.914])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.fixation import get_fixations_dict_from_fixation_df, get_heatmap\n",
    "\n",
    "data = 'E:\\XAMI-MIMIC\\patient_10011607\\REFLACX\\P300R471381\\\\fixations.csv'\n",
    "trans = 'E:\\XAMI-MIMIC\\patient_10011607\\REFLACX\\P300R471381\\\\timestamps_transcription.csv'\n",
    "\n",
    "get_fixations_dict_from_fixation_df(pd.read_csv(data), pd.read_csv(trans), rad_speaking=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CPU]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "labels_cols = DEFAULT_REFLACX_LABEL_COLS\n",
    "iou_thrs = np.array([0.5])\n",
    "\n",
    "common_args = {\n",
    "    \"save_early_stop_model\": True,\n",
    "    \"optimiser\": \"sgd\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"image_backbone_pretrained\": True,\n",
    "    \"heatmap_backbone_pretrained\": True,\n",
    "    \"record_training_performance\": True,\n",
    "    \"image_size\": 512,\n",
    "    \"batch_size\": 4,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"reduceLROnPlateau_factor\": 0.1,\n",
    "    \"reduceLROnPlateau_patience\": 999,\n",
    "    \"reduceLROnPlateau_full_stop\": True,\n",
    "    \"multiStepLR_milestones\": 100,\n",
    "    \"multiStepLR_gamma\": 0.1,\n",
    "    \"use_mask\": True,\n",
    "    \"gt_in_train_till\": 999,\n",
    "    \"box_head_dropout_rate\": 0,\n",
    "    \"measure_test\": True,\n",
    "}\n",
    "\n",
    "fusion_add_args = {\n",
    "    \"fuse_depth\": 0,\n",
    "    \"fusion_residule\": False,\n",
    "    \"fusion_strategy\": \"add\", \n",
    "}\n",
    "\n",
    "small_model_args = {\n",
    "    \"mask_hidden_layers\": 64,\n",
    "    \"fuse_conv_channels\": 64,\n",
    "    \"representation_size\": 64, \n",
    "    \"backbone_out_channels\": 64,\n",
    "}\n",
    "\n",
    "mobilenet_args = {\n",
    "    \"backbone\": \"resnet18\",\n",
    "    \"using_fpn\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_setups = [\n",
    "    # ModelSetup(\n",
    "    #     name=\"CXR_images_pupil\",\n",
    "    #     use_heatmaps=True,\n",
    "    #     with_pupil=True,\n",
    "    #     **mobilenet_args,\n",
    "    #     **small_model_args,\n",
    "    #     **common_args,\n",
    "    #     **fusion_add_args,\n",
    "    # ),\n",
    "    # ModelSetup(\n",
    "    #     name=\"CXR_images_fixations\",\n",
    "    #     use_heatmaps=True,\n",
    "    #     with_fixations=True,\n",
    "    #     **mobilenet_args,\n",
    "    #     **small_model_args,\n",
    "    #     **common_args,\n",
    "    #     **fusion_add_args,\n",
    "    # ), \n",
    "    # ModelSetup(\n",
    "    #     name=\"CXR_images_fixations_1third\",\n",
    "    #     use_heatmaps=True,\n",
    "    #     with_1st_third_fixations=True,\n",
    "    #     **mobilenet_args,\n",
    "    #     **small_model_args,\n",
    "    #     **common_args,\n",
    "    #     **fusion_add_args,\n",
    "    # ), \n",
    "    ModelSetup(\n",
    "        name=\"CXR_images_fixations_silence\",\n",
    "        use_heatmaps=True,\n",
    "        with_rad_silence=True,\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **fusion_add_args,\n",
    "    ), \n",
    "    ModelSetup(\n",
    "        name=\"CXR_images_fixations_speaking\",\n",
    "        use_heatmaps=True,\n",
    "        with_rad_speaking=True,\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **fusion_add_args,\n",
    "    ), \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "train_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Preparing for the training.====================\n",
      "Using pretrained backbone. resnet18\n",
      "Using pretrained backbone. resnet18\n",
      "CXR_images_fixations_silence will use mask, [64] layers.\n",
      "Dataloader creating...\n",
      "Dataloader created!!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4548/3109491593.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mtrain_coco\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     train_coco, val_coco, test_coco = get_cocos(\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\VIMMI\\Desktop\\multimodal-abnormalities-detection\\utils\\coco_utils.py\u001b[0m in \u001b[0;36mget_cocos\u001b[1;34m(train_dataloader, val_dataloader, test_dataloader)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_cocos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_coco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mval_coco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtest_coco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\VIMMI\\Desktop\\multimodal-abnormalities-detection\\utils\\coco_utils.py\u001b[0m in \u001b[0;36mget_coco_api_from_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_coco_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\VIMMI\\Desktop\\multimodal-abnormalities-detection\\utils\\coco_utils.py\u001b[0m in \u001b[0;36mconvert_to_coco_api\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# targets = ds.get_annotations(img_idx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m# img, clinical_num, clinical_cat, targets = ds[img_idx]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\VIMMI\\Desktop\\multimodal-abnormalities-detection\\data\\datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[0mimg_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\VIMMI\\Desktop\\multimodal-abnormalities-detection\\data\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, image, target, fixation)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "## we have to mention that in order to provide objective evaluation, we compromise the dataset size, which also nagatively afftect the performance and generlaization.\n",
    "\n",
    "for model_setup in all_model_setups:\n",
    "\n",
    "    print_f.print_title(\"Preparing for the training.\")\n",
    "\n",
    "    train_info = TrainingInfo(model_setup)\n",
    "\n",
    "    if model_setup.measure_test:\n",
    "        # initialise the test recording list.\n",
    "        train_info.test_ap_ars = []\n",
    "\n",
    "    model = create_multimodal_rcnn_model(\n",
    "        labels_cols,\n",
    "        model_setup,\n",
    "        rpn_nms_thresh=0.3,\n",
    "        box_detections_per_img=10,\n",
    "        box_nms_thresh=0.2,\n",
    "        rpn_score_thresh=0.0,\n",
    "        box_score_thresh=0.05,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    ################ Datasets ################\n",
    "    dataset_params_dict = {\n",
    "        \"XAMI_MIMIC_PATH\": XAMI_MIMIC_PATH,\n",
    "        \"with_fixations\": model_setup.with_fixations,\n",
    "        \"with_pupil\": model_setup.with_pupil,\n",
    "        \"with_1st_third_fixations\": model_setup.with_1st_third_fixations,\n",
    "        'with_rad_silence': model_setup.with_rad_silence,\n",
    "        'with_rad_speaking': model_setup.with_rad_speaking,\n",
    "        \"bbox_to_mask\": model_setup.use_mask,\n",
    "        \"labels_cols\": labels_cols,\n",
    "    }\n",
    "\n",
    "    print(\"Dataloader creating...\")\n",
    "\n",
    "    detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "        dataset_params_dict=dataset_params_dict,\n",
    "    )\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "        train_dataset, val_dataset, test_dataset, batch_size=model_setup.batch_size,\n",
    "    )\n",
    "\n",
    "    print(\"Dataloader created!!\")\n",
    "\n",
    "    train_coco= None\n",
    "\n",
    "    train_coco, val_coco, test_coco = get_cocos(\n",
    "        train_dataloader, val_dataloader, test_dataloader\n",
    "    )\n",
    "\n",
    "    eval_params_dict = get_eval_params_dict(\n",
    "        detect_eval_dataset, iou_thrs=iou_thrs, use_iobb=use_iobb,\n",
    "    )\n",
    "\n",
    "    # dynamic_loss_weight = None\n",
    "    loss_keys = [\n",
    "        \"loss_classifier\",\n",
    "        \"loss_box_reg\",\n",
    "        \"loss_objectness\",\n",
    "        \"loss_rpn_box_reg\",\n",
    "    ]\n",
    "    \n",
    "    dynamic_loss_weight = DynamicWeightedLoss(\n",
    "        keys=loss_keys + [\"loss_mask\"] if model_setup.use_mask else loss_keys\n",
    "    )\n",
    "    dynamic_loss_weight.to(device)\n",
    "    print_params_setup(model)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if dynamic_loss_weight:\n",
    "        params += [p for p in dynamic_loss_weight.parameters() if p.requires_grad]\n",
    "\n",
    "    iou_types = get_iou_types(model, model_setup)\n",
    "    optimizer = get_optimiser(params, model_setup)\n",
    "    lr_scheduler = get_lr_scheduler(optimizer, model_setup)\n",
    "\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    print_f.print_title(\n",
    "        f\"Start training. Preparing Took [{ (current_time - train_info.start_t).seconds}] sec\"\n",
    "    )\n",
    "\n",
    "    train_info.start_t = datetime.now()\n",
    "\n",
    "    val_loss = None\n",
    "\n",
    "    ## Start the training from here.\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        print_f.print_title(f\"Training model: [{model_setup.name}]\")\n",
    "        print(train_info)\n",
    "\n",
    "        train_info.epoch = e + 1\n",
    "\n",
    "        if train_info.epoch > model_setup.gt_in_train_till:\n",
    "            model.roi_heads.use_gt_in_train  = False\n",
    "\n",
    "        ###### Perform training and show the training result here ######\n",
    "        model.train()\n",
    "\n",
    "        train_info.last_train_evaluator, train_loger = xami_train_one_epoch(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_dataloader,\n",
    "            device=device,\n",
    "            epoch=train_info.epoch,\n",
    "            print_freq=10,\n",
    "            iou_types=iou_types,\n",
    "            coco=train_coco,\n",
    "            score_thres=None,\n",
    "            evaluate_on_run=True,\n",
    "            params_dict=eval_params_dict,\n",
    "            dynamic_loss_weight=dynamic_loss_weight,\n",
    "        )\n",
    "\n",
    "        # train_info.train_evaluators.append(train_evaluator)\n",
    "        train_info.train_losses.append(get_data_from_metric_logger(train_loger))\n",
    "        ################################################################\n",
    "\n",
    "        ####### Put the model into evaluation mode, start evaluating the current model #######\n",
    "        model.eval()\n",
    "\n",
    "        train_info.last_val_evaluator, val_logger = xami_evaluate(\n",
    "            model=model,\n",
    "            data_loader=val_dataloader,\n",
    "            device=device,\n",
    "            params_dict=eval_params_dict,\n",
    "            coco=val_coco,\n",
    "            iou_types=iou_types,\n",
    "            score_thres=None,\n",
    "        )\n",
    "\n",
    "        # train_info.val_evaluators.append(val_evaluator)\n",
    "        train_info.val_losses.append(get_data_from_metric_logger(val_logger))\n",
    "\n",
    "        train_ap_ar, val_ap_ar = get_ap_ar_for_train_val(\n",
    "            train_info.last_train_evaluator,\n",
    "            train_info.last_val_evaluator,\n",
    "            areaRng=\"all\",\n",
    "            iouThr=0.5,\n",
    "            maxDets=10,\n",
    "        )\n",
    "\n",
    "        train_info.train_ap_ars.append(train_ap_ar)\n",
    "        train_info.val_ap_ars.append(val_ap_ar)\n",
    "\n",
    "        if model_setup.measure_test:\n",
    "            train_info.test_evaluator, test_logger = xami_evaluate(\n",
    "                model=model,\n",
    "                data_loader=test_dataloader,\n",
    "                device=device,\n",
    "                params_dict=eval_params_dict,\n",
    "                coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "            )\n",
    "            train_info.test_losses.append(get_data_from_metric_logger(test_logger))\n",
    "            test_ap_ar = get_ap_ar(\n",
    "                train_info.test_evaluator, areaRng=\"all\", iouThr=0.5, maxDets=10,\n",
    "            )\n",
    "            train_info.test_ap_ars.append(test_ap_ar)\n",
    "\n",
    "        ### update the learning rate\n",
    "\n",
    "        val_loss = train_info.val_losses[-1][\"loss\"]\n",
    "\n",
    "        if train_info.epoch > model_setup.warmup_epochs:\n",
    "            if not lr_scheduler is None:\n",
    "                if isinstance(lr_scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    if (\n",
    "                        model_setup.reduceLROnPlateau_full_stop\n",
    "                        and lr_scheduler.num_bad_epochs\n",
    "                        >= model_setup.reduceLROnPlateau_patience\n",
    "                    ):\n",
    "                        print_f.print_title(\n",
    "                            f\"| EarlyStop | Epoch [{train_info.epoch}] Done | It has took [{sec_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec |\"\n",
    "                        )\n",
    "                        break\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "        ## Clean everything before we show the evaluating result in this stage, so we can inspect the training progress.\n",
    "        clear_output()\n",
    "\n",
    "        # if model_setup.record_training_performance:\n",
    "        plot_ap_ars(\n",
    "            train_ap_ars=train_info.train_ap_ars,\n",
    "            val_ap_ars=train_info.val_ap_ars,\n",
    "            test_ap_ars=train_info.test_ap_ars,\n",
    "        )\n",
    "\n",
    "        plot_losses(train_info.train_losses, train_info.val_losses, test_logers=train_info.test_losses)\n",
    "\n",
    "        previous_time = current_time\n",
    "        current_time = datetime.now()\n",
    "        epoch_took = current_time - previous_time\n",
    "\n",
    "        sec_took = (current_time - train_info.start_t).seconds\n",
    "        speed = sec_took / train_info.epoch\n",
    "\n",
    "        print_str = f\"| Epoch [{train_info.epoch}] Done | It has took [{sec_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec | \"\n",
    "\n",
    "        if lr_scheduler and hasattr(lr_scheduler, \"num_bad_epochs\"):\n",
    "            print_str += f\"Patience [{lr_scheduler.num_bad_epochs}] |\"\n",
    "\n",
    "        print_f.print_title(print_str)\n",
    "\n",
    "        #######################################################################################\n",
    "        if model_setup.save_early_stop_model:\n",
    "            val_ar, val_ap, train_info = check_best(\n",
    "                val_ap_ar=val_ap_ar,\n",
    "                device=device,\n",
    "                eval_params_dict=eval_params_dict,\n",
    "                train_info=train_info,\n",
    "                model=model,\n",
    "                optim=optimizer,\n",
    "                test_dataloader=test_dataloader,\n",
    "                test_coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "                dynamic_weight=dynamic_loss_weight,\n",
    "            )\n",
    "\n",
    "    val_ap_ar = get_ap_ar(train_info.last_val_evaluator)\n",
    "\n",
    "    train_info = end_train(\n",
    "        train_info=train_info,\n",
    "        model=model,\n",
    "        optim=optimizer,\n",
    "        eval_params_dict=eval_params_dict,\n",
    "        last_val_ar=val_ap_ar[\"ar\"],\n",
    "        last_val_ap=val_ap_ar[\"ap\"],\n",
    "        test_dataloader=test_dataloader,\n",
    "        device=device,\n",
    "        test_coco=test_coco,\n",
    "        iou_types=iou_types,\n",
    "        score_thres=None,\n",
    "        dynamic_weight=dynamic_loss_weight,\n",
    "    )\n",
    "\n",
    "    train_infos.append(train_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_info in train_infos:\n",
    "#     print(train_info)\n",
    "#     model_setup = train_info.model_setup\n",
    "#     model = create_multimodal_rcnn_model(\n",
    "#         labels_cols,\n",
    "#         model_setup,\n",
    "#         rpn_nms_thresh=0.3,\n",
    "#         box_detections_per_img=10,\n",
    "#         box_nms_thresh=0.2,\n",
    "#         rpn_score_thresh=0.0,\n",
    "#         box_score_thresh=0.05,\n",
    "#     )\n",
    "#     print_params_setup(model)\n",
    "#     print(f\"Max AP on test: [{max([ap_ar['ap']  for ap_ar in  train_info.test_ap_ars]):.4f}]\")\n",
    "#     plot_ap_ars(\n",
    "#             train_ap_ars=train_info.train_ap_ars,\n",
    "#             val_ap_ars=train_info.val_ap_ars,\n",
    "#             test_ap_ars=train_info.test_ap_ars,\n",
    "#         )\n",
    "\n",
    "#     plot_losses(train_info.train_losses, train_info.val_losses, test_logers=train_info.test_losses)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2b4c68e18acfab416f9980befd91f6d572217495ef701c2da267a02b76310ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
